diff --git a/eval.py b/eval.py
index 8174794f63c4a284f988ae88c07ad0d3072cf3ed..80f696f770fdc52eb74bb4f28ac4a89b3cf4addd 100644
--- a/eval.py
+++ b/eval.py
@@ -174,52 +174,59 @@ def main():
 
     attacker_side, defender_side = roll_off_attacker_defender(
         manual_roll_allowed=False,
         log_fn=None,
     )
     deploy_only_war(
         model_units=model_units,
         enemy_units=enemy_units,
         b_len=env.unwrapped.b_len,
         b_hei=env.unwrapped.b_hei,
         attacker_side=attacker_side,
         log_fn=None,
     )
     post_deploy_setup(log_fn=None)
     env.attacker_side = attacker_side
     env.defender_side = defender_side
 
     state, info = env.reset(m=model_units, e=enemy_units, Type="big", trunc=True)
     n_actions = [5, 2, len(info["player health"]), len(info["player health"]), 5, len(info["model health"])]
     for _ in range(len(model_units)):
         n_actions.append(12)
     n_observations = len(state)
 
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
 
-    policy_net = DQN(n_observations, n_actions).to(device)
-    target_net = DQN(n_observations, n_actions).to(device)
+    net_type = checkpoint.get("net_type") if isinstance(checkpoint, dict) else None
+    dueling = net_type == "dueling"
+    if not dueling and isinstance(checkpoint, dict):
+        policy_state = checkpoint.get("policy_net", {})
+        if any(key.startswith("value_heads.") for key in policy_state):
+            dueling = True
+
+    policy_net = DQN(n_observations, n_actions, dueling=dueling).to(device)
+    target_net = DQN(n_observations, n_actions, dueling=dueling).to(device)
     optimizer = torch.optim.Adam(policy_net.parameters())
 
     policy_net.load_state_dict(checkpoint["policy_net"])
     target_net.load_state_dict(checkpoint["target_net"])
     optimizer.load_state_dict(checkpoint["optimizer"])
 
     policy_net.eval()
     target_net.eval()
 
     log(f"Старт оценки: игр={games}, epsilon={epsilon:.3f}.")
 
     wins = 0
     vp_diffs = []
     end_reasons = Counter()
 
     for idx in range(1, games + 1):
         winner, end_reason, vp_diff = run_episode(
             env, model_units, enemy_units, policy_net, epsilon, device
         )
         vp_diffs.append(vp_diff)
         end_reasons[end_reason] += 1
         if winner == "model":
             wins += 1
         log(f"Игра {idx}/{games}: winner={winner} vp_diff={vp_diff} end_reason={end_reason}")
 

