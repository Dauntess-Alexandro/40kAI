Model units:
Name: Canoptek Scarab Swarms, Army Type: Necrons
Name: Canoptek Scarab Swarms, Army Type: Necrons
Enemy units:
Name: Canoptek Scarab Swarms, Army Type: Necrons
Name: Canoptek Scarab Swarms, Army Type: Necrons
Number of Lifetimes ran: 100

Iteration 0 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 1 ended with reward tensor([0.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 1
Iteration 2 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 1
Iteration 3 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 1
Iteration 4 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 5, victory condition 1
Iteration 5 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 7, victory condition 1
Iteration 6 ended with reward tensor([-5.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 9, victory condition 1
Iteration 7 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 10.0], model VP 0, enemy VP 11, victory condition 1
Iteration 8 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [5.0, 10.0], model VP 0, enemy VP 13, victory condition 1
Iteration 9 ended with reward tensor([-1.3000]), enemy health [12, 6.0], model health [1.0, 6.0], model VP 0, enemy VP 2, victory condition 1
enemy won!
Slay and Secure Victory Condition
enemy won!
Iteration 10 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 3
Iteration 11 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 3
Iteration 12 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 6, victory condition 3
Iteration 13 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 8, victory condition 3
Iteration 14 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 10, victory condition 3
Iteration 15 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 12, victory condition 3
Iteration 16 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 14, victory condition 3
Iteration 17 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 16, victory condition 3
Iteration 18 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 18, victory condition 3
Iteration 19 ended with reward tensor([-2.5000]), enemy health [12, 12], model health [12, 6.0], model VP 0, enemy VP 20, victory condition 3
enemy won!
Domination Victory Condition
enemy won!
Iteration 20 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 3
Iteration 21 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [9.0, 12], model VP 0, enemy VP 4, victory condition 3
Iteration 22 ended with reward tensor([0.7000]), enemy health [12, 9.0], model health [4.0, 12], model VP 0, enemy VP 5, victory condition 3
Iteration 23 ended with reward tensor([-0.5000]), enemy health [12, 9.0], model health [0.0, 12], model VP 0, enemy VP 6, victory condition 3
Iteration 24 ended with reward tensor([-1.5000]), enemy health [12, 9.0], model health [0.0, 12], model VP 0, enemy VP 7, victory condition 3
Iteration 25 ended with reward tensor([0.7000]), enemy health [5.0, 9.0], model health [0.0, 6.0], model VP 0, enemy VP 8, victory condition 3
Iteration 26 ended with reward tensor([1.]), enemy health [0, 9.0], model health [0.0, 5.0], model VP 0, enemy VP 9, victory condition 3
Iteration 27 ended with reward tensor([0.]), enemy health [0, 9.0], model health [0.0, 2.0], model VP 0, enemy VP 10, victory condition 3
Iteration 28 ended with reward tensor([-1]), enemy health [0, 9.0], model health [0.0, 2.0], model VP 0, enemy VP 11, victory condition 3
Iteration 29 ended with reward tensor([-2]), enemy health [0, 9.0], model health [0, 2.0], model VP 0, enemy VP 12, victory condition 3
enemy won!
Domination Victory Condition
enemy won!
Iteration 30 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 1
Iteration 31 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 1
Iteration 32 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 1
Iteration 33 ended with reward tensor([1.]), enemy health [12, 7.0], model health [12, 12], model VP 0, enemy VP 4, victory condition 1
Iteration 34 ended with reward tensor([0.7000]), enemy health [12, 1.0], model health [12, 8.0], model VP 0, enemy VP 5, victory condition 1
Iteration 35 ended with reward tensor([1.]), enemy health [12, 0], model health [12, 4.0], model VP 0, enemy VP 6, victory condition 1
Iteration 36 ended with reward tensor([0]), enemy health [12, 0], model health [12, 4.0], model VP 0, enemy VP 7, victory condition 1
Iteration 37 ended with reward tensor([-4.]), enemy health [12, 0], model health [12, 4.0], model VP 0, enemy VP 8, victory condition 1
Iteration 38 ended with reward tensor([1.]), enemy health [12, 0], model health [12, 1.0], model VP 0, enemy VP 9, victory condition 1
Iteration 39 ended with reward tensor([-3]), enemy health [12, 0], model health [12, 0], model VP 0, enemy VP 1, victory condition 1
enemy won!
Slay and Secure Victory Condition
enemy won!
Iteration 40 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 3
Iteration 41 ended with reward tensor([-0.5000]), enemy health [11.0, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 3
Iteration 42 ended with reward tensor([-0.5000]), enemy health [11.0, 12], model health [12, 10.0], model VP 0, enemy VP 3, victory condition 3
Iteration 43 ended with reward tensor([-0.5000]), enemy health [11.0, 12], model health [10.0, 10.0], model VP 0, enemy VP 4, victory condition 3
Iteration 44 ended with reward tensor([0.5000]), enemy health [11.0, 12], model health [10.0, 10.0], model VP 0, enemy VP 5, victory condition 3
Iteration 45 ended with reward tensor([0]), enemy health [11.0, 12], model health [10.0, 10.0], model VP 0, enemy VP 6, victory condition 3
Iteration 46 ended with reward tensor([-0.5000]), enemy health [11.0, 12], model health [10.0, 7.0], model VP 0, enemy VP 7, victory condition 3
Iteration 47 ended with reward tensor([0]), enemy health [11.0, 12], model health [10.0, 1.0], model VP 0, enemy VP 8, victory condition 3
Iteration 48 ended with reward tensor([-2]), enemy health [11.0, 12], model health [10.0, 0], model VP 0, enemy VP 9, victory condition 3
Iteration 49 ended with reward tensor([-5.]), enemy health [11.0, 12], model health [10.0, 0], model VP 0, enemy VP 10, victory condition 3
enemy won!
Domination Victory Condition
enemy won!
Iteration 50 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 51 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 2
Iteration 52 ended with reward tensor([-1.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 2
Iteration 53 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 6.0], model VP 0, enemy VP 4, victory condition 2
Iteration 54 ended with reward tensor([0.7000]), enemy health [12, 9.0], model health [7.0, 1.0], model VP 0, enemy VP 5, victory condition 2
Iteration 55 ended with reward tensor([-1]), enemy health [12, 9.0], model health [3.0, 0], model VP 0, enemy VP 6, victory condition 2
Iteration 56 ended with reward tensor([-4]), enemy health [12, 9.0], model health [0.0, 0], model VP 0, enemy VP 7, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 57 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 58 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 2
Iteration 59 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 2
Iteration 60 ended with reward tensor([0.7000]), enemy health [9.0, 12], model health [9.0, 12], model VP 0, enemy VP 4, victory condition 2
Iteration 61 ended with reward tensor([0.7000]), enemy health [2.0, 12], model health [5.0, 12], model VP 0, enemy VP 5, victory condition 2
Iteration 62 ended with reward tensor([1.]), enemy health [0.0, 12], model health [0.0, 12], model VP 0, enemy VP 6, victory condition 2
Iteration 63 ended with reward tensor([-0.5000]), enemy health [0.0, 12], model health [0.0, 12], model VP 0, enemy VP 7, victory condition 2
Iteration 64 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 8.0], model VP 0, enemy VP 8, victory condition 2
Iteration 65 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 6.0], model VP 0, enemy VP 9, victory condition 2
Iteration 66 ended with reward tensor([-4]), enemy health [0.0, 7.0], model health [0.0, 0.0], model VP 0, enemy VP 10, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 67 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 68 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 2
Iteration 69 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 9.0], model VP 0, enemy VP 3, victory condition 2
Iteration 70 ended with reward tensor([0.7000]), enemy health [12, 6.0], model health [12, 3.0], model VP 0, enemy VP 4, victory condition 2
Iteration 71 ended with reward tensor([-2]), enemy health [12, 6.0], model health [10.0, 0], model VP 0, enemy VP 5, victory condition 2
Iteration 72 ended with reward tensor([-1]), enemy health [12, 6.0], model health [10.0, 0], model VP 0, enemy VP 6, victory condition 2
Iteration 73 ended with reward tensor([-3.]), enemy health [12, 6.0], model health [1.0, 0], model VP 0, enemy VP 7, victory condition 2
Iteration 74 ended with reward tensor([-4]), enemy health [12, 6.0], model health [0, 0], model VP 0, enemy VP 8, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 75 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 1
Iteration 76 ended with reward tensor([0.7000]), enemy health [12, 10.0], model health [7.0, 12], model VP 0, enemy VP 2, victory condition 1
Iteration 77 ended with reward tensor([0.7000]), enemy health [12, 9.0], model health [1.0, 12], model VP 0, enemy VP 3, victory condition 1
Iteration 78 ended with reward tensor([-0.5000]), enemy health [12, 9.0], model health [0, 12], model VP 0, enemy VP 4, victory condition 1
Iteration 79 ended with reward tensor([0.7000]), enemy health [7.0, 9.0], model health [0, 9.0], model VP 0, enemy VP 5, victory condition 1
Iteration 80 ended with reward tensor([0]), enemy health [7.0, 9.0], model health [0, 3.0], model VP 0, enemy VP 6, victory condition 1
Iteration 81 ended with reward tensor([-4]), enemy health [7.0, 9.0], model health [0, 0.0], model VP 0, enemy VP 7, victory condition 1
enemy won!
Major Victory
enemy won!
Iteration 82 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 83 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 2
Iteration 84 ended with reward tensor([0.7000]), enemy health [8.0, 12], model health [8.0, 12], model VP 0, enemy VP 5, victory condition 2
Iteration 85 ended with reward tensor([-0.5000]), enemy health [8.0, 12], model health [3.0, 12], model VP 0, enemy VP 7, victory condition 2
Iteration 86 ended with reward tensor([0.7000]), enemy health [5.0, 12], model health [0.0, 12], model VP 0, enemy VP 9, victory condition 2
Iteration 87 ended with reward tensor([-0.5000]), enemy health [5.0, 12], model health [0.0, 12], model VP 0, enemy VP 11, victory condition 2
Iteration 88 ended with reward tensor([0.7000]), enemy health [5.0, 9.0], model health [0.0, 11.0], model VP 0, enemy VP 13, victory condition 2
Iteration 89 ended with reward tensor([0.7000]), enemy health [5.0, 9.0], model health [0.0, 9.0], model VP 0, enemy VP 15, victory condition 2
Iteration 90 ended with reward tensor([0.7000]), enemy health [5.0, 4.0], model health [0.0, 4.0], model VP 0, enemy VP 17, victory condition 2
Iteration 91 ended with reward tensor([-4]), enemy health [5.0, 4.0], model health [0.0, 0], model VP 0, enemy VP 19, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 92 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 3
Iteration 93 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 3
Iteration 94 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 6, victory condition 3
Iteration 95 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 8, victory condition 3
Iteration 96 ended with reward tensor([0.5000]), enemy health [10.0, 12], model health [12, 12], model VP 0, enemy VP 10, victory condition 3
Iteration 97 ended with reward tensor([-0.5000]), enemy health [10.0, 12], model health [12, 11.0], model VP 0, enemy VP 12, victory condition 3
Iteration 98 ended with reward tensor([0.7000]), enemy health [6.0, 9.0], model health [12, 6.0], model VP 0, enemy VP 14, victory condition 3
Iteration 99 ended with reward tensor([1.]), enemy health [6.0, 0.0], model health [10.0, 6.0], model VP 0, enemy VP 16, victory condition 3
Iteration 100 ended with reward tensor([0]), enemy health [6.0, 0.0], model health [10.0, 2.0], model VP 0, enemy VP 18, victory condition 3
Iteration 101 ended with reward tensor([-1.3000]), enemy health [4.0, 0.0], model health [7.0, 2.0], model VP 0, enemy VP 20, victory condition 3
enemy won!
Domination Victory Condition
enemy won!
Iteration 102 ended with reward tensor([1.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 1
Iteration 103 ended with reward tensor([0.7000]), enemy health [7.0, 12], model health [12, 9.0], model VP 0, enemy VP 3, victory condition 1
Iteration 104 ended with reward tensor([-0.5000]), enemy health [7.0, 12], model health [12, 7.0], model VP 0, enemy VP 4, victory condition 1
Iteration 105 ended with reward tensor([0]), enemy health [7.0, 12], model health [12, 7.0], model VP 0, enemy VP 5, victory condition 1
Iteration 106 ended with reward tensor([-0.5000]), enemy health [7.0, 12], model health [8.0, 7.0], model VP 0, enemy VP 6, victory condition 1
Iteration 107 ended with reward tensor([0.7000]), enemy health [7.0, 6.0], model health [2.0, 5.0], model VP 0, enemy VP 7, victory condition 1
Iteration 108 ended with reward tensor([0.7000]), enemy health [7.0, 2.0], model health [0, 1.0], model VP 0, enemy VP 8, victory condition 1
Iteration 109 ended with reward tensor([-1.]), enemy health [7.0, 2.0], model health [0, 1.0], model VP 0, enemy VP 9, victory condition 1
Iteration 110 ended with reward tensor([-4]), enemy health [7.0, 2.0], model health [0, 0], model VP 0, enemy VP 10, victory condition 1
enemy won!
Major Victory
enemy won!
Iteration 111 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 112 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 2
Iteration 113 ended with reward tensor([1.]), enemy health [12, 11.0], model health [12, 12], model VP 0, enemy VP 3, victory condition 2
Iteration 114 ended with reward tensor([-0.5000]), enemy health [12, 11.0], model health [7.0, 12], model VP 0, enemy VP 4, victory condition 2
Iteration 115 ended with reward tensor([0.7000]), enemy health [9.0, 11.0], model health [7.0, 12], model VP 0, enemy VP 5, victory condition 2
Iteration 116 ended with reward tensor([-0.5000]), enemy health [9.0, 11.0], model health [5.0, 12], model VP 0, enemy VP 6, victory condition 2
Iteration 117 ended with reward tensor([0.7000]), enemy health [9.0, 7.0], model health [0, 12], model VP 0, enemy VP 7, victory condition 2
Iteration 118 ended with reward tensor([-0.5000]), enemy health [9.0, 7.0], model health [0, 12], model VP 0, enemy VP 8, victory condition 2
Iteration 119 ended with reward tensor([-0.5000]), enemy health [9.0, 7.0], model health [0, 12], model VP 0, enemy VP 9, victory condition 2
Iteration 120 ended with reward tensor([-2.5000]), enemy health [9.0, 7.0], model health [0, 6.0], model VP 0, enemy VP 10, victory condition 2
enemy won!
Ancient Relic Victory Condition
enemy won!
Iteration 121 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 3
Iteration 122 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 3
Iteration 123 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 3
Iteration 124 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 3
Iteration 125 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 7.0], model VP 0, enemy VP 5, victory condition 3
Iteration 126 ended with reward tensor([0]), enemy health [12, 12], model health [12, 5.0], model VP 0, enemy VP 6, victory condition 3
Iteration 127 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 5.0], model VP 0, enemy VP 7, victory condition 3
Iteration 128 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [10.0, 1.0], model VP 0, enemy VP 8, victory condition 3
Iteration 129 ended with reward tensor([-1]), enemy health [12, 12], model health [7.0, 0], model VP 0, enemy VP 9, victory condition 3
Iteration 130 ended with reward tensor([-3]), enemy health [12, 12], model health [3.0, 0], model VP 0, enemy VP 10, victory condition 3
enemy won!
Domination Victory Condition
enemy won!
Iteration 131 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 132 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 2
Iteration 133 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 2
Iteration 134 ended with reward tensor([1.]), enemy health [12, 8.0], model health [12, 12], model VP 0, enemy VP 4, victory condition 2
Iteration 135 ended with reward tensor([-0.5000]), enemy health [12, 8.0], model health [12, 7.0], model VP 0, enemy VP 5, victory condition 2
Iteration 136 ended with reward tensor([0.5000]), enemy health [12, 8.0], model health [12, 7.0], model VP 0, enemy VP 6, victory condition 2
Iteration 137 ended with reward tensor([-4.]), enemy health [12, 8.0], model health [12, 7.0], model VP 0, enemy VP 7, victory condition 2
Iteration 138 ended with reward tensor([0.7000]), enemy health [9.0, 7.0], model health [10.0, 7.0], model VP 0, enemy VP 8, victory condition 2
Iteration 139 ended with reward tensor([1.]), enemy health [9.0, 0], model health [5.0, 7.0], model VP 0, enemy VP 9, victory condition 2
Iteration 140 ended with reward tensor([-2]), enemy health [9.0, 0], model health [5.0, 3.0], model VP 0, enemy VP 10, victory condition 2
enemy won!
Ancient Relic Victory Condition
enemy won!
Iteration 141 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 142 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 2
Iteration 143 ended with reward tensor([0.]), enemy health [3.0, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 2
Iteration 144 ended with reward tensor([-0.5000]), enemy health [3.0, 12], model health [12, 9.0], model VP 0, enemy VP 4, victory condition 2
Iteration 145 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [12, 4.0], model VP 0, enemy VP 5, victory condition 2
Iteration 146 ended with reward tensor([-0.5000]), enemy health [3.0, 7.0], model health [7.0, 3.0], model VP 0, enemy VP 6, victory condition 2
Iteration 147 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [2.0, 1.0], model VP 0, enemy VP 7, victory condition 2
Iteration 148 ended with reward tensor([-4]), enemy health [2.0, 7.0], model health [0, 0.0], model VP 0, enemy VP 8, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 149 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 3
Iteration 150 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 3
Iteration 151 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 3
Iteration 152 ended with reward tensor([-5.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 6, victory condition 3
Iteration 153 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 8, victory condition 3
Iteration 154 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 10, victory condition 3
Iteration 155 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 12, victory condition 3
Iteration 156 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 14, victory condition 3
Iteration 157 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 16, victory condition 3
Iteration 158 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 18, victory condition 3
enemy won!
Domination Victory Condition
enemy won!
Iteration 159 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 2
Iteration 160 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 2
Iteration 161 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 6, victory condition 2
Iteration 162 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 8, victory condition 2
Iteration 163 ended with reward tensor([1.]), enemy health [12, 11.0], model health [12, 12], model VP 0, enemy VP 10, victory condition 2
Iteration 164 ended with reward tensor([0.7000]), enemy health [9.0, 8.0], model health [9.0, 7.0], model VP 0, enemy VP 12, victory condition 2
Iteration 165 ended with reward tensor([0.7000]), enemy health [6.0, 5.0], model health [3.0, 4.0], model VP 0, enemy VP 14, victory condition 2
Iteration 166 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [1.0, 1.0], model VP 0, enemy VP 16, victory condition 2
Iteration 167 ended with reward tensor([-1]), enemy health [2.0, 0.0], model health [1.0, 0], model VP 0, enemy VP 18, victory condition 2
Iteration 168 ended with reward tensor([-3.]), enemy health [2.0, 0.0], model health [1.0, 0], model VP 0, enemy VP 20, victory condition 2
enemy won!
Ancient Relic Victory Condition
enemy won!
Iteration 169 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 3
Iteration 170 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 3
Iteration 171 ended with reward tensor([0.7000]), enemy health [10.0, 12], model health [9.0, 10.0], model VP 0, enemy VP 6, victory condition 3
Iteration 172 ended with reward tensor([0.7000]), enemy health [7.0, 12], model health [3.0, 10.0], model VP 0, enemy VP 8, victory condition 3
Iteration 173 ended with reward tensor([-0.5000]), enemy health [7.0, 12], model health [0, 10.0], model VP 0, enemy VP 10, victory condition 3
Iteration 174 ended with reward tensor([-1]), enemy health [7.0, 12], model health [0, 10.0], model VP 0, enemy VP 12, victory condition 3
Iteration 175 ended with reward tensor([0.7000]), enemy health [7.0, 11.0], model health [0.0, 4.0], model VP 0, enemy VP 14, victory condition 3
Iteration 176 ended with reward tensor([0]), enemy health [7.0, 11.0], model health [0.0, 1.0], model VP 0, enemy VP 16, victory condition 3
Iteration 177 ended with reward tensor([-4]), enemy health [7.0, 11.0], model health [0.0, 0], model VP 0, enemy VP 18, victory condition 3
enemy won!
Major Victory
enemy won!
Iteration 178 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 1
Iteration 179 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 1
Iteration 180 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 6, victory condition 1
Iteration 181 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 8, victory condition 1
Iteration 182 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 10, victory condition 1
Iteration 183 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [8.0, 12], model VP 0, enemy VP 12, victory condition 1
Iteration 184 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [6.0, 12], model VP 0, enemy VP 14, victory condition 1
Iteration 185 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [3.0, 8.0], model VP 0, enemy VP 16, victory condition 1
Iteration 186 ended with reward tensor([-1]), enemy health [12, 12], model health [3.0, 0.0], model VP 0, enemy VP 18, victory condition 1
Iteration 187 ended with reward tensor([-5.]), enemy health [12, 12], model health [3.0, 0.0], model VP 0, enemy VP 2, victory condition 1
enemy won!
Slay and Secure Victory Condition
enemy won!
Iteration 188 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 2
Iteration 189 ended with reward tensor([1.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 2
Iteration 190 ended with reward tensor([1.5000]), enemy health [12, 11.0], model health [12, 12], model VP 0, enemy VP 6, victory condition 2
Iteration 191 ended with reward tensor([0.7000]), enemy health [5.0, 11.0], model health [8.0, 7.0], model VP 0, enemy VP 8, victory condition 2
Iteration 192 ended with reward tensor([-0.5000]), enemy health [5.0, 11.0], model health [7.0, 6.0], model VP 0, enemy VP 10, victory condition 2
Iteration 193 ended with reward tensor([0.7000]), enemy health [2.0, 11.0], model health [1.0, 6.0], model VP 0, enemy VP 12, victory condition 2
Iteration 194 ended with reward tensor([-0.5000]), enemy health [2.0, 11.0], model health [1.0, 6.0], model VP 0, enemy VP 14, victory condition 2
Iteration 195 ended with reward tensor([0]), enemy health [2.0, 11.0], model health [1.0, 6.0], model VP 0, enemy VP 16, victory condition 2
Iteration 196 ended with reward tensor([1.]), enemy health [0, 11.0], model health [1.0, 3.0], model VP 0, enemy VP 18, victory condition 2
Iteration 197 ended with reward tensor([-3]), enemy health [0, 11.0], model health [1.0, 0], model VP 0, enemy VP 20, victory condition 2
enemy won!
Ancient Relic Victory Condition
enemy won!
Iteration 198 ended with reward tensor([-4.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 2
Iteration 199 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 2
Iteration 200 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [9.0, 12], model VP 0, enemy VP 6, victory condition 2
Iteration 201 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [5.0, 12], model VP 0, enemy VP 8, victory condition 2
Iteration 202 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [3.0, 11.0], model VP 0, enemy VP 10, victory condition 2
Iteration 203 ended with reward tensor([0.7000]), enemy health [12, 5.0], model health [3.0, 4.0], model VP 0, enemy VP 12, victory condition 2
Iteration 204 ended with reward tensor([-1]), enemy health [12, 5.0], model health [3.0, 0], model VP 0, enemy VP 14, victory condition 2
Iteration 205 ended with reward tensor([-4]), enemy health [12, 5.0], model health [0, 0], model VP 0, enemy VP 16, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 206 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 1
Iteration 207 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 1
Iteration 208 ended with reward tensor([-5.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 6, victory condition 1
Iteration 209 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 8, victory condition 1
Iteration 210 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 10, victory condition 1
Iteration 211 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 12, victory condition 1
Iteration 212 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 14, victory condition 1
Iteration 213 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 16, victory condition 1
Iteration 214 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 18, victory condition 1
Iteration 215 ended with reward tensor([-3]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 1
enemy won!
Slay and Secure Victory Condition
enemy won!
Iteration 216 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 3
Iteration 217 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 3
Iteration 218 ended with reward tensor([0.5000]), enemy health [12, 7.0], model health [12, 12], model VP 0, enemy VP 6, victory condition 3
Iteration 219 ended with reward tensor([-0.5000]), enemy health [12, 7.0], model health [7.0, 12], model VP 0, enemy VP 8, victory condition 3
Iteration 220 ended with reward tensor([-0.5000]), enemy health [12, 7.0], model health [2.0, 12], model VP 0, enemy VP 10, victory condition 3
Iteration 221 ended with reward tensor([-0.5000]), enemy health [12, 7.0], model health [2.0, 10.0], model VP 0, enemy VP 11, victory condition 3
Iteration 222 ended with reward tensor([-0.5000]), enemy health [12, 7.0], model health [0, 6.0], model VP 0, enemy VP 12, victory condition 3
Iteration 223 ended with reward tensor([-4]), enemy health [12, 7.0], model health [0, 0], model VP 0, enemy VP 13, victory condition 3
enemy won!
Major Victory
enemy won!
Iteration 224 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 3
Iteration 225 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 3
Iteration 226 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 3
Iteration 227 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 3
Iteration 228 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 5, victory condition 3
Iteration 229 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 6, victory condition 3
Iteration 230 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 7, victory condition 3
Iteration 231 ended with reward tensor([0.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 8, victory condition 3
Iteration 232 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 11.0], model VP 0, enemy VP 9, victory condition 3
Iteration 233 ended with reward tensor([-1.3000]), enemy health [12, 6.0], model health [12, 9.0], model VP 0, enemy VP 10, victory condition 3
enemy won!
Domination Victory Condition
enemy won!
Iteration 234 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 1
Iteration 235 ended with reward tensor([0.7000]), enemy health [12, 6.0], model health [11.0, 12], model VP 0, enemy VP 2, victory condition 1
Iteration 236 ended with reward tensor([0.7000]), enemy health [8.0, 6.0], model health [3.0, 12], model VP 0, enemy VP 3, victory condition 1
Iteration 237 ended with reward tensor([0.7000]), enemy health [7.0, 6.0], model health [0.0, 12], model VP 0, enemy VP 4, victory condition 1
Iteration 238 ended with reward tensor([-0.5000]), enemy health [7.0, 6.0], model health [0.0, 12], model VP 0, enemy VP 5, victory condition 1
Iteration 239 ended with reward tensor([-0.5000]), enemy health [7.0, 6.0], model health [0.0, 8.0], model VP 0, enemy VP 6, victory condition 1
Iteration 240 ended with reward tensor([0]), enemy health [7.0, 6.0], model health [0.0, 2.0], model VP 0, enemy VP 7, victory condition 1
Iteration 241 ended with reward tensor([-4]), enemy health [7.0, 6.0], model health [0.0, 0], model VP 0, enemy VP 8, victory condition 1
enemy won!
Major Victory
enemy won!
Iteration 242 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 3
Iteration 243 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 3
Iteration 244 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 3
Iteration 245 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 3
Iteration 246 ended with reward tensor([-1.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 5, victory condition 3
Iteration 247 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 6, victory condition 3
Iteration 248 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [8.0, 12], model VP 0, enemy VP 7, victory condition 3
Iteration 249 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [8.0, 12], model VP 0, enemy VP 8, victory condition 3
Iteration 250 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [8.0, 8.0], model VP 0, enemy VP 9, victory condition 3
Iteration 251 ended with reward tensor([-3]), enemy health [12, 12], model health [8.0, 8.0], model VP 0, enemy VP 10, victory condition 3
enemy won!
Domination Victory Condition
enemy won!
Iteration 252 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 253 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 2
Iteration 254 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 2
Iteration 255 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 2
Iteration 256 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 5, victory condition 2
Iteration 257 ended with reward tensor([0.]), enemy health [12, 10.0], model health [12, 12], model VP 0, enemy VP 6, victory condition 2
Iteration 258 ended with reward tensor([-0.5000]), enemy health [12, 10.0], model health [6.0, 9.0], model VP 0, enemy VP 7, victory condition 2
Iteration 259 ended with reward tensor([0]), enemy health [12, 10.0], model health [6.0, 1.0], model VP 0, enemy VP 8, victory condition 2
Iteration 260 ended with reward tensor([-1]), enemy health [12, 10.0], model health [6.0, 0], model VP 0, enemy VP 9, victory condition 2
Iteration 261 ended with reward tensor([-4.5000]), enemy health [12, 10.0], model health [2.0, 0], model VP 0, enemy VP 10, victory condition 2
enemy won!
Ancient Relic Victory Condition
enemy won!
Iteration 262 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 263 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 9.0], model VP 0, enemy VP 2, victory condition 2
Iteration 264 ended with reward tensor([0.7000]), enemy health [10.0, 12], model health [6.0, 9.0], model VP 0, enemy VP 3, victory condition 2
Iteration 265 ended with reward tensor([-0.5000]), enemy health [10.0, 12], model health [0, 9.0], model VP 0, enemy VP 4, victory condition 2
Iteration 266 ended with reward tensor([-0.5000]), enemy health [10.0, 12], model health [0, 6.0], model VP 0, enemy VP 5, victory condition 2
Iteration 267 ended with reward tensor([0]), enemy health [10.0, 12], model health [0, 3.0], model VP 0, enemy VP 6, victory condition 2
Iteration 268 ended with reward tensor([-4]), enemy health [10.0, 12], model health [0, 0.0], model VP 0, enemy VP 7, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 269 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 1
Iteration 270 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 1
Iteration 271 ended with reward tensor([0.5000]), enemy health [12, 11.0], model health [12, 12], model VP 0, enemy VP 3, victory condition 1
Iteration 272 ended with reward tensor([-0.5000]), enemy health [12, 11.0], model health [8.0, 12], model VP 0, enemy VP 4, victory condition 1
Iteration 273 ended with reward tensor([-1]), enemy health [12, 11.0], model health [8.0, 12], model VP 0, enemy VP 5, victory condition 1
Iteration 274 ended with reward tensor([0.7000]), enemy health [12.0, 11.0], model health [1.0, 12], model VP 0, enemy VP 6, victory condition 1
Iteration 275 ended with reward tensor([0.7000]), enemy health [9.0, 11.0], model health [0, 12], model VP 0, enemy VP 7, victory condition 1
Iteration 276 ended with reward tensor([-0.5000]), enemy health [9.0, 11.0], model health [0, 12], model VP 0, enemy VP 8, victory condition 1
Iteration 277 ended with reward tensor([-0.5000]), enemy health [9.0, 11.0], model health [0, 10.0], model VP 0, enemy VP 9, victory condition 1
Iteration 278 ended with reward tensor([-2.5000]), enemy health [9.0, 11.0], model health [0, 7.0], model VP 0, enemy VP 1, victory condition 1
enemy won!
Slay and Secure Victory Condition
enemy won!
Iteration 279 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 3
Iteration 280 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 3
Iteration 281 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 3
Iteration 282 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 6.0], model VP 0, enemy VP 4, victory condition 3
Iteration 283 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [4.0, 6.0], model VP 0, enemy VP 5, victory condition 3
Iteration 284 ended with reward tensor([0]), enemy health [12, 12], model health [0, 4.0], model VP 0, enemy VP 6, victory condition 3
Iteration 285 ended with reward tensor([-4]), enemy health [12, 12], model health [0, 0], model VP 0, enemy VP 7, victory condition 3
enemy won!
Major Victory
enemy won!
Iteration 286 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 3
Iteration 287 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 3
Iteration 288 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 3
Iteration 289 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 3
Iteration 290 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 5, victory condition 3
Iteration 291 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [10.0, 12], model VP 0, enemy VP 6, victory condition 3
Iteration 292 ended with reward tensor([0.7000]), enemy health [10.0, 12], model health [10.0, 9.0], model VP 0, enemy VP 7, victory condition 3
Iteration 293 ended with reward tensor([0.7000]), enemy health [7.0, 12], model health [10.0, 5.0], model VP 0, enemy VP 8, victory condition 3
Iteration 294 ended with reward tensor([0.7000]), enemy health [4.0, 12], model health [10.0, 3.0], model VP 0, enemy VP 9, victory condition 3
Iteration 295 ended with reward tensor([-2.5000]), enemy health [4.0, 12], model health [10.0, 2.0], model VP 0, enemy VP 10, victory condition 3
enemy won!
Domination Victory Condition
enemy won!
Iteration 296 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 297 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 2
Iteration 298 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 2
Iteration 299 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 2
Iteration 300 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [9.0, 12], model VP 0, enemy VP 5, victory condition 2
Iteration 301 ended with reward tensor([0.]), enemy health [12, 12], model health [9.0, 12], model VP 0, enemy VP 6, victory condition 2
Iteration 302 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [4.0, 12], model VP 0, enemy VP 7, victory condition 2
Iteration 303 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [0, 6.0], model VP 0, enemy VP 8, victory condition 2
Iteration 304 ended with reward tensor([0]), enemy health [12, 12], model health [0, 3.0], model VP 0, enemy VP 9, victory condition 2
Iteration 305 ended with reward tensor([-4]), enemy health [12, 12], model health [0, 0.0], model VP 0, enemy VP 10, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 306 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 307 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 2
Iteration 308 ended with reward tensor([0.7000]), enemy health [12, 10.0], model health [8.0, 12], model VP 0, enemy VP 3, victory condition 2
Iteration 309 ended with reward tensor([-0.5000]), enemy health [12, 10.0], model health [8.0, 12], model VP 0, enemy VP 4, victory condition 2
Iteration 310 ended with reward tensor([0.]), enemy health [4.0, 10.0], model health [8.0, 12], model VP 0, enemy VP 5, victory condition 2
Iteration 311 ended with reward tensor([0.7000]), enemy health [4.0, 1.0], model health [8.0, 11.0], model VP 0, enemy VP 6, victory condition 2
Iteration 312 ended with reward tensor([1.]), enemy health [4.0, 0], model health [8.0, 6.0], model VP 0, enemy VP 7, victory condition 2
Iteration 313 ended with reward tensor([-1.5000]), enemy health [4.0, 0], model health [8.0, 0], model VP 0, enemy VP 8, victory condition 2
Iteration 314 ended with reward tensor([-2]), enemy health [4.0, 0], model health [8.0, 0], model VP 0, enemy VP 9, victory condition 2
Iteration 315 ended with reward tensor([-4]), enemy health [4.0, 0], model health [2.0, 0], model VP 0, enemy VP 10, victory condition 2
enemy won!
Ancient Relic Victory Condition
enemy won!
Iteration 316 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 1
Iteration 317 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 1
Iteration 318 ended with reward tensor([0.7000]), enemy health [12, 7.0], model health [11.0, 12], model VP 0, enemy VP 3, victory condition 1
Iteration 319 ended with reward tensor([0.7000]), enemy health [12, 1.0], model health [9.0, 12], model VP 0, enemy VP 4, victory condition 1
Iteration 320 ended with reward tensor([-0.5000]), enemy health [12, 1.0], model health [2.0, 12], model VP 0, enemy VP 5, victory condition 1
Iteration 321 ended with reward tensor([0]), enemy health [12, 1.0], model health [2.0, 12], model VP 0, enemy VP 6, victory condition 1
Iteration 322 ended with reward tensor([-0.5000]), enemy health [12, 1.0], model health [2.0, 12], model VP 0, enemy VP 7, victory condition 1
Iteration 323 ended with reward tensor([-1]), enemy health [12, 1.0], model health [2.0, 12], model VP 0, enemy VP 8, victory condition 1
Iteration 324 ended with reward tensor([0.7000]), enemy health [6.0, 1.0], model health [2.0, 10.0], model VP 0, enemy VP 9, victory condition 1
Iteration 325 ended with reward tensor([-3.5000]), enemy health [6.0, 1.0], model health [2.0, 10.0], model VP 0, enemy VP 1, victory condition 1
enemy won!
Slay and Secure Victory Condition
enemy won!
Iteration 326 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 3
Iteration 327 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 3
Iteration 328 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 3
Iteration 329 ended with reward tensor([1.5000]), enemy health [7.0, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 3
Iteration 330 ended with reward tensor([0.7000]), enemy health [7.0, 6.0], model health [12, 8.0], model VP 0, enemy VP 5, victory condition 3
Iteration 331 ended with reward tensor([-0.5000]), enemy health [7.0, 6.0], model health [12, 5.0], model VP 0, enemy VP 6, victory condition 3
Iteration 332 ended with reward tensor([-2]), enemy health [7.0, 6.0], model health [12, 0.0], model VP 0, enemy VP 7, victory condition 3
Iteration 333 ended with reward tensor([-2.5000]), enemy health [7.0, 6.0], model health [6.0, 0.0], model VP 0, enemy VP 8, victory condition 3
Iteration 334 ended with reward tensor([-1]), enemy health [7.0, 6.0], model health [1.0, 0.0], model VP 0, enemy VP 9, victory condition 3
Iteration 335 ended with reward tensor([-4.5000]), enemy health [7.0, 6.0], model health [0, 0.0], model VP 0, enemy VP 10, victory condition 3
enemy won!
Major Victory
enemy won!
Iteration 336 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 337 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 2
Iteration 338 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 2
Iteration 339 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 9.0], model VP 0, enemy VP 4, victory condition 2
Iteration 340 ended with reward tensor([0.7000]), enemy health [12, 7.0], model health [12, 6.0], model VP 0, enemy VP 5, victory condition 2
Iteration 341 ended with reward tensor([1.2000]), enemy health [12, 3.0], model health [12, 3.0], model VP 0, enemy VP 6, victory condition 2
Iteration 342 ended with reward tensor([2.]), enemy health [10.0, 0], model health [10.0, 3.0], model VP 0, enemy VP 7, victory condition 2
Iteration 343 ended with reward tensor([0.7000]), enemy health [7.0, 0], model health [3.0, 3.0], model VP 0, enemy VP 8, victory condition 2
Iteration 344 ended with reward tensor([0.7000]), enemy health [5.0, 0], model health [2.0, 3.0], model VP 0, enemy VP 9, victory condition 2
Iteration 345 ended with reward tensor([-1.3000]), enemy health [3.0, 0], model health [0, 3.0], model VP 0, enemy VP 10, victory condition 2
enemy won!
Ancient Relic Victory Condition
enemy won!
Iteration 346 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 1
Iteration 347 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 1
Iteration 348 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 1
Iteration 349 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 1
Iteration 350 ended with reward tensor([1.]), enemy health [5.0, 12], model health [12, 12], model VP 0, enemy VP 5, victory condition 1
Iteration 351 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [12, 6.0], model VP 0, enemy VP 6, victory condition 1
Iteration 352 ended with reward tensor([-0.5000]), enemy health [5.0, 6.0], model health [12, 4.0], model VP 0, enemy VP 7, victory condition 1
Iteration 353 ended with reward tensor([1.]), enemy health [5.0, 0.0], model health [7.0, 1.0], model VP 0, enemy VP 8, victory condition 1
Iteration 354 ended with reward tensor([-1.5000]), enemy health [5.0, 0.0], model health [7.0, 0], model VP 0, enemy VP 9, victory condition 1
Iteration 355 ended with reward tensor([-3]), enemy health [5.0, 0.0], model health [7.0, 0], model VP 0, enemy VP 1, victory condition 1
enemy won!
Slay and Secure Victory Condition
enemy won!
Iteration 356 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 1
Iteration 357 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 9.0], model VP 0, enemy VP 2, victory condition 1
Iteration 358 ended with reward tensor([-4.]), enemy health [12, 10.0], model health [12, 9.0], model VP 0, enemy VP 3, victory condition 1
Iteration 359 ended with reward tensor([-0.5000]), enemy health [12, 10.0], model health [9.0, 7.0], model VP 0, enemy VP 4, victory condition 1
Iteration 360 ended with reward tensor([-1]), enemy health [12, 10.0], model health [9.0, 0], model VP 0, enemy VP 5, victory condition 1
Iteration 361 ended with reward tensor([-1]), enemy health [12, 10.0], model health [9.0, 0], model VP 0, enemy VP 6, victory condition 1
Iteration 362 ended with reward tensor([-2]), enemy health [12, 10.0], model health [9.0, 0], model VP 0, enemy VP 7, victory condition 1
Iteration 363 ended with reward tensor([-2.5000]), enemy health [12, 10.0], model health [9.0, 0], model VP 0, enemy VP 8, victory condition 1
Iteration 364 ended with reward tensor([-1]), enemy health [12, 10.0], model health [6.0, 0], model VP 0, enemy VP 9, victory condition 1
Iteration 365 ended with reward tensor([-4]), enemy health [12, 10.0], model health [0, 0], model VP 0, enemy VP 10, victory condition 1
enemy won!
Major Victory
enemy won!
Iteration 366 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 367 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 10.0], model VP 0, enemy VP 2, victory condition 2
Iteration 368 ended with reward tensor([0.7000]), enemy health [12, 10.0], model health [6.0, 10.0], model VP 0, enemy VP 3, victory condition 2
Iteration 369 ended with reward tensor([0.7000]), enemy health [12, 10.0], model health [4.0, 10.0], model VP 0, enemy VP 4, victory condition 2
Iteration 370 ended with reward tensor([0.7000]), enemy health [12, 7.0], model health [4.0, 10.0], model VP 0, enemy VP 5, victory condition 2
Iteration 371 ended with reward tensor([0.7000]), enemy health [12, 5.0], model health [4.0, 10.0], model VP 0, enemy VP 6, victory condition 2
Iteration 372 ended with reward tensor([1.]), enemy health [12, 0.0], model health [4.0, 10.0], model VP 0, enemy VP 7, victory condition 2
Iteration 373 ended with reward tensor([0.5000]), enemy health [12, 0.0], model health [4.0, 10.0], model VP 0, enemy VP 8, victory condition 2
Iteration 374 ended with reward tensor([-5.]), enemy health [12, 0.0], model health [4.0, 10.0], model VP 0, enemy VP 9, victory condition 2
Iteration 375 ended with reward tensor([-1.3000]), enemy health [8.0, 0.0], model health [4.0, 6.0], model VP 0, enemy VP 10, victory condition 2
enemy won!
Ancient Relic Victory Condition
enemy won!
Iteration 376 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 377 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 2
Iteration 378 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 3, victory condition 2
Iteration 379 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 4, victory condition 2
Iteration 380 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 5, victory condition 2
Iteration 381 ended with reward tensor([0.7000]), enemy health [12, 7.0], model health [10.0, 10.0], model VP 0, enemy VP 6, victory condition 2
Iteration 382 ended with reward tensor([0.7000]), enemy health [12, 2.0], model health [5.0, 7.0], model VP 0, enemy VP 7, victory condition 2
Iteration 383 ended with reward tensor([-0.5000]), enemy health [12, 2.0], model health [0, 1.0], model VP 0, enemy VP 8, victory condition 2
Iteration 384 ended with reward tensor([-4]), enemy health [12, 2.0], model health [0, 0.0], model VP 0, enemy VP 9, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 385 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 1
Iteration 386 ended with reward tensor([-1.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 1
Iteration 387 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 10.0], model VP 0, enemy VP 3, victory condition 1
Iteration 388 ended with reward tensor([0.7000]), enemy health [12, 8.0], model health [12, 9.0], model VP 0, enemy VP 4, victory condition 1
Iteration 389 ended with reward tensor([-0.5000]), enemy health [12, 8.0], model health [12, 8.0], model VP 0, enemy VP 5, victory condition 1
Iteration 390 ended with reward tensor([0]), enemy health [12, 8.0], model health [12, 5.0], model VP 0, enemy VP 6, victory condition 1
Iteration 391 ended with reward tensor([-0.5000]), enemy health [12, 8.0], model health [8.0, 5.0], model VP 0, enemy VP 7, victory condition 1
Iteration 392 ended with reward tensor([0]), enemy health [12, 8.0], model health [8.0, 2.0], model VP 0, enemy VP 8, victory condition 1
Iteration 393 ended with reward tensor([0]), enemy health [12, 8.0], model health [8.0, 2.0], model VP 0, enemy VP 9, victory condition 1
Iteration 394 ended with reward tensor([-4]), enemy health [12, 8.0], model health [8.0, 0], model VP 0, enemy VP 1, victory condition 1
enemy won!
Slay and Secure Victory Condition
enemy won!
Iteration 395 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 1
Iteration 396 ended with reward tensor([0.7000]), enemy health [12, 9.0], model health [3.0, 12], model VP 0, enemy VP 2, victory condition 1
Iteration 397 ended with reward tensor([0.7000]), enemy health [12, 4.0], model health [0.0, 12], model VP 0, enemy VP 3, victory condition 1
Iteration 398 ended with reward tensor([0.7000]), enemy health [12, 1.0], model health [0.0, 12], model VP 0, enemy VP 4, victory condition 1
Iteration 399 ended with reward tensor([1.]), enemy health [12, 0], model health [0.0, 12], model VP 0, enemy VP 5, victory condition 1
Iteration 400 ended with reward tensor([-0.5000]), enemy health [12, 0], model health [0.0, 9.0], model VP 0, enemy VP 6, victory condition 1
Iteration 401 ended with reward tensor([0.7000]), enemy health [10.0, 0], model health [0, 9.0], model VP 0, enemy VP 7, victory condition 1
Iteration 402 ended with reward tensor([0.7000]), enemy health [6.0, 0], model health [0, 9.0], model VP 0, enemy VP 8, victory condition 1
Iteration 403 ended with reward tensor([0.7000]), enemy health [3.0, 0], model health [0, 9.0], model VP 0, enemy VP 9, victory condition 1
Iteration 404 ended with reward tensor([-2.5000]), enemy health [3.0, 0], model health [0, 9.0], model VP 0, enemy VP 1, victory condition 1
enemy won!
Slay and Secure Victory Condition
enemy won!
Iteration 405 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 1
Iteration 406 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 2, victory condition 1
Iteration 407 ended with reward tensor([0.7000]), enemy health [5.0, 12], model health [12, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 408 ended with reward tensor([0.7000]), enemy health [1.0, 12], model health [12, 1.0], model VP 0, enemy VP 4, victory condition 1
Iteration 409 ended with reward tensor([-1]), enemy health [1.0, 12], model health [12, 0.0], model VP 0, enemy VP 5, victory condition 1
Iteration 410 ended with reward tensor([-1]), enemy health [1.0, 12], model health [12, 0.0], model VP 0, enemy VP 6, victory condition 1
Iteration 411 ended with reward tensor([-2]), enemy health [1.0, 12], model health [7.0, 0.0], model VP 0, enemy VP 7, victory condition 1
Iteration 412 ended with reward tensor([-4]), enemy health [1.0, 12], model health [0.0, 0.0], model VP 0, enemy VP 8, victory condition 1
enemy won!
Major Victory
enemy won!
Iteration 413 ended with reward tensor([1.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 1, victory condition 2
Iteration 414 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 7.0], model VP 0, enemy VP 2, victory condition 2
Iteration 415 ended with reward tensor([0.5000]), enemy health [6.0, 12], model health [12, 7.0], model VP 0, enemy VP 3, victory condition 2
Iteration 416 ended with reward tensor([0.]), enemy health [2.0, 12], model health [12, 7.0], model VP 0, enemy VP 4, victory condition 2
Iteration 417 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [12, 2.0], model VP 0, enemy VP 4, victory condition 2
Iteration 418 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [7.0, 2.0], model VP 0, enemy VP 4, victory condition 2
Iteration 419 ended with reward tensor([-0.5000]), enemy health [0, 3.0], model health [4.0, 2.0], model VP 0, enemy VP 4, victory condition 2
Iteration 420 ended with reward tensor([-2]), enemy health [0, 3.0], model health [4.0, 0], model VP 0, enemy VP 4, victory condition 2
Iteration 421 ended with reward tensor([-1]), enemy health [0, 3.0], model health [4.0, 0], model VP 0, enemy VP 4, victory condition 2
Iteration 422 ended with reward tensor([-5.]), enemy health [0, 3.0], model health [4.0, 0], model VP 0, enemy VP 4, victory condition 2
enemy won!
Ancient Relic Victory Condition
enemy won!
Iteration 423 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 424 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 425 ended with reward tensor([0.7000]), enemy health [8.0, 12], model health [8.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 426 ended with reward tensor([0.7000]), enemy health [3.0, 12], model health [7.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 427 ended with reward tensor([-0.5000]), enemy health [3.0, 12], model health [6.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 428 ended with reward tensor([-0.5000]), enemy health [3.0, 12], model health [6.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 429 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 430 ended with reward tensor([-0.5000]), enemy health [3.0, 7.0], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 431 ended with reward tensor([-0.5000]), enemy health [3.0, 7.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 432 ended with reward tensor([-1.3000]), enemy health [3.0, 5.0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 1
draw!
Slay and Secure Victory Condition
enemy won!
Iteration 433 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 434 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 435 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 436 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 437 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 438 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 439 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [7.0, 9.0], model VP 0, enemy VP 0, victory condition 3
Iteration 440 ended with reward tensor([0.7000]), enemy health [12, 4.0], model health [7.0, 5.0], model VP 0, enemy VP 0, victory condition 3
Iteration 441 ended with reward tensor([0.5000]), enemy health [12, 4.0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 3
Iteration 442 ended with reward tensor([-1.]), enemy health [12, 0.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 3
draw!
Domination Victory Condition
enemy won!
Iteration 443 ended with reward tensor([-5.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 444 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 445 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [10.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 446 ended with reward tensor([0.7000]), enemy health [7.0, 7.0], model health [6.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 447 ended with reward tensor([-0.5000]), enemy health [7.0, 7.0], model health [6.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 448 ended with reward tensor([0.7000]), enemy health [7.0, 6.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 449 ended with reward tensor([0.7000]), enemy health [7.0, 4.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 450 ended with reward tensor([1.]), enemy health [7.0, 0.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 451 ended with reward tensor([-1.5000]), enemy health [7.0, 0.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 452 ended with reward tensor([-2.5000]), enemy health [7.0, 0.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 3
draw!
Domination Victory Condition
enemy won!
Iteration 453 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 454 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 455 ended with reward tensor([0.7000]), enemy health [7.0, 9.0], model health [7.0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 456 ended with reward tensor([1.]), enemy health [7.0, 0.0], model health [3.0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 457 ended with reward tensor([-0.5000]), enemy health [7.0, 0.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 458 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 459 ended with reward tensor([3.]), enemy health [0.0, 0.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
model won!
Major Victory
model won!
Iteration 460 ended with reward tensor([-5.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 461 ended with reward tensor([1.]), enemy health [12, 8.0], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 462 ended with reward tensor([-2.]), enemy health [12, 6.0], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 463 ended with reward tensor([-4.]), enemy health [12, 6.0], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 464 ended with reward tensor([0.7000]), enemy health [12, 1.0], model health [4.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 465 ended with reward tensor([-0.5000]), enemy health [12, 1.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 466 ended with reward tensor([1.]), enemy health [12, 0], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 467 ended with reward tensor([0.7000]), enemy health [8.0, 0], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 468 ended with reward tensor([0.7000]), enemy health [1.0, 0], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 469 ended with reward tensor([3.]), enemy health [0, 0], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 1
model won!
Major Victory
model won!
Iteration 470 ended with reward tensor([-5.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 471 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 472 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 473 ended with reward tensor([0.7000]), enemy health [7.0, 12], model health [12, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 474 ended with reward tensor([-1]), enemy health [7.0, 12], model health [12, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 475 ended with reward tensor([-3.]), enemy health [7.0, 12], model health [12, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 476 ended with reward tensor([-0.5000]), enemy health [7.0, 12], model health [12, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 477 ended with reward tensor([-2]), enemy health [7.0, 12], model health [10.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 478 ended with reward tensor([-2.5000]), enemy health [7.0, 12], model health [10.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 479 ended with reward tensor([-3.5000]), enemy health [7.0, 12], model health [10.0, 0], model VP 0, enemy VP 0, victory condition 1
draw!
Slay and Secure Victory Condition
enemy won!
Iteration 480 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 481 ended with reward tensor([-4.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 482 ended with reward tensor([-4.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 483 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 484 ended with reward tensor([0.7000]), enemy health [12, 9.0], model health [12, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 485 ended with reward tensor([0.7000]), enemy health [12, 4.0], model health [12, 6.0], model VP 0, enemy VP 0, victory condition 2
Iteration 486 ended with reward tensor([-1]), enemy health [12, 4.0], model health [12, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 487 ended with reward tensor([-0.5000]), enemy health [12, 4.0], model health [8.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 488 ended with reward tensor([-0.5000]), enemy health [12, 4.0], model health [4.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 489 ended with reward tensor([-4]), enemy health [12, 4.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 490 ended with reward tensor([1.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 491 ended with reward tensor([-5.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 492 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [9.0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 493 ended with reward tensor([0.7000]), enemy health [9.0, 12], model health [4.0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 494 ended with reward tensor([-0.5000]), enemy health [9.0, 12], model health [0.0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 495 ended with reward tensor([-0.5000]), enemy health [9.0, 12], model health [0.0, 10.0], model VP 0, enemy VP 0, victory condition 2
Iteration 496 ended with reward tensor([0.7000]), enemy health [5.0, 12], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 497 ended with reward tensor([0.7000]), enemy health [1.0, 12], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 498 ended with reward tensor([1.]), enemy health [0, 12], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 499 ended with reward tensor([-4]), enemy health [0, 12], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 500 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 501 ended with reward tensor([0.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 502 ended with reward tensor([2.]), enemy health [8.0, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 503 ended with reward tensor([0.7000]), enemy health [5.0, 10.0], model health [12, 7.0], model VP 0, enemy VP 0, victory condition 3
Iteration 504 ended with reward tensor([0]), enemy health [5.0, 10.0], model health [12, 2.0], model VP 0, enemy VP 0, victory condition 3
Iteration 505 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [3.0, 2.0], model VP 0, enemy VP 0, victory condition 3
Iteration 506 ended with reward tensor([0.7000]), enemy health [5.0, 1.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 3
Iteration 507 ended with reward tensor([1.]), enemy health [5.0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 3
Iteration 508 ended with reward tensor([-4]), enemy health [5.0, 0], model health [0, 0], model VP 0, enemy VP 0, victory condition 3
enemy won!
Major Victory
enemy won!
Iteration 509 ended with reward tensor([-5.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 510 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [7.0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 511 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [5.0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 512 ended with reward tensor([0.7000]), enemy health [12, 10.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 513 ended with reward tensor([-2.5000]), enemy health [9.0, 10.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 514 ended with reward tensor([0.7000]), enemy health [2.0, 10.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 515 ended with reward tensor([-4]), enemy health [2.0, 10.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 516 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 517 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 518 ended with reward tensor([0.7000]), enemy health [12, 10.0], model health [10.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 519 ended with reward tensor([0.7000]), enemy health [12, 9.0], model health [10.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 520 ended with reward tensor([-0.5000]), enemy health [12, 9.0], model health [4.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 521 ended with reward tensor([-0.5000]), enemy health [12, 9.0], model health [4.0, 10.0], model VP 0, enemy VP 0, victory condition 3
Iteration 522 ended with reward tensor([0.7000]), enemy health [12, 7.0], model health [4.0, 7.0], model VP 0, enemy VP 0, victory condition 3
Iteration 523 ended with reward tensor([0.7000]), enemy health [12, 4.0], model health [0.0, 6.0], model VP 0, enemy VP 0, victory condition 3
Iteration 524 ended with reward tensor([0]), enemy health [12, 4.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 3
Iteration 525 ended with reward tensor([-4]), enemy health [12, 4.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 3
enemy won!
Major Victory
enemy won!
Iteration 526 ended with reward tensor([-5.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 527 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 528 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 529 ended with reward tensor([-4.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 530 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 531 ended with reward tensor([-4.5000]), enemy health [10.0, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 532 ended with reward tensor([-0.5000]), enemy health [10.0, 12], model health [9.0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 533 ended with reward tensor([0.7000]), enemy health [6.0, 12], model health [9.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 534 ended with reward tensor([0.7000]), enemy health [5.0, 12], model health [9.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 535 ended with reward tensor([-3]), enemy health [5.0, 12], model health [9.0, 0], model VP 0, enemy VP 0, victory condition 2
draw!
Ancient Relic Victory Condition
enemy won!
Iteration 536 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 537 ended with reward tensor([-5.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 538 ended with reward tensor([0.5000]), enemy health [12, 11.0], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 539 ended with reward tensor([-2.5000]), enemy health [12, 11.0], model health [6.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 540 ended with reward tensor([0.7000]), enemy health [12, 9.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 541 ended with reward tensor([0.7000]), enemy health [12, 5.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 542 ended with reward tensor([-0.5000]), enemy health [12, 5.0], model health [0.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 543 ended with reward tensor([0.7000]), enemy health [12, 1.0], model health [0.0, 8.0], model VP 0, enemy VP 0, victory condition 3
Iteration 544 ended with reward tensor([-0.5000]), enemy health [12, 1.0], model health [0.0, 6.0], model VP 0, enemy VP 0, victory condition 3
Iteration 545 ended with reward tensor([-1.3000]), enemy health [9.0, 1.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 3
draw!
Domination Victory Condition
enemy won!
Iteration 546 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 547 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 548 ended with reward tensor([-2.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 549 ended with reward tensor([0.7000]), enemy health [12, 7.0], model health [10.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 550 ended with reward tensor([0.7000]), enemy health [12, 5.0], model health [6.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 551 ended with reward tensor([0.7000]), enemy health [10.0, 5.0], model health [0.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 552 ended with reward tensor([0.7000]), enemy health [5.0, 5.0], model health [0.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 553 ended with reward tensor([-0.5000]), enemy health [5.0, 5.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 554 ended with reward tensor([1.]), enemy health [5.0, 0.0], model health [0, 6.0], model VP 0, enemy VP 0, victory condition 3
Iteration 555 ended with reward tensor([-1.3000]), enemy health [5.0, 0.0], model health [0.0, 6.0], model VP 0, enemy VP 0, victory condition 3
draw!
Domination Victory Condition
enemy won!
Iteration 556 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 557 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 558 ended with reward tensor([0.7000]), enemy health [10.0, 12], model health [12, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 559 ended with reward tensor([0.]), enemy health [2.0, 12], model health [12, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 560 ended with reward tensor([1.]), enemy health [0, 12], model health [4.0, 6.0], model VP 0, enemy VP 0, victory condition 1
Iteration 561 ended with reward tensor([-3.]), enemy health [0, 12], model health [4.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 562 ended with reward tensor([-2]), enemy health [0, 12], model health [4.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 563 ended with reward tensor([-1]), enemy health [0, 12], model health [4.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 564 ended with reward tensor([-4]), enemy health [0, 12], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
enemy won!
Major Victory
enemy won!
Iteration 565 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 566 ended with reward tensor([-2.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 567 ended with reward tensor([0.7000]), enemy health [12, 6.0], model health [9.0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 568 ended with reward tensor([0.7000]), enemy health [12, 2.0], model health [4.0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 569 ended with reward tensor([1.]), enemy health [12, 0], model health [2.0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 570 ended with reward tensor([0.7000]), enemy health [9.0, 0], model health [0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 571 ended with reward tensor([0.7000]), enemy health [6.0, 0], model health [0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 572 ended with reward tensor([-0.5000]), enemy health [6.0, 0], model health [0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 573 ended with reward tensor([0.7000]), enemy health [2.0, 0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 574 ended with reward tensor([3.]), enemy health [0.0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
model won!
Major Victory
model won!
Iteration 575 ended with reward tensor([-5.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 576 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 577 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 578 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [6.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 579 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [0.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 580 ended with reward tensor([0.7000]), enemy health [12, 5.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 581 ended with reward tensor([0.7000]), enemy health [12, 3.0], model health [0.0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 582 ended with reward tensor([-4]), enemy health [12, 3.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
enemy won!
Major Victory
enemy won!
Iteration 583 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 584 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 585 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 586 ended with reward tensor([-2.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 587 ended with reward tensor([0.7000]), enemy health [12, 8.0], model health [7.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 588 ended with reward tensor([-0.5000]), enemy health [12, 8.0], model health [7.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 589 ended with reward tensor([0.7000]), enemy health [12, 6.0], model health [1.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 590 ended with reward tensor([-0.5000]), enemy health [12, 6.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 591 ended with reward tensor([-0.5000]), enemy health [12, 6.0], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 3
Iteration 592 ended with reward tensor([-2.5000]), enemy health [12, 6.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 3
draw!
Domination Victory Condition
enemy won!
Iteration 593 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 594 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 595 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 596 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 597 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 598 ended with reward tensor([0.7000]), enemy health [12, 9.0], model health [12, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 599 ended with reward tensor([0]), enemy health [12, 9.0], model health [12, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 600 ended with reward tensor([-3.]), enemy health [12, 9.0], model health [8.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 601 ended with reward tensor([-3.]), enemy health [12, 9.0], model health [4.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 602 ended with reward tensor([-4]), enemy health [12, 9.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 603 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 604 ended with reward tensor([0.7000]), enemy health [12, 7.0], model health [6.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 605 ended with reward tensor([0.7000]), enemy health [12, 2.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 606 ended with reward tensor([-4]), enemy health [12, 2.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 607 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 608 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 609 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 610 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 611 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 612 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 613 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 614 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 615 ended with reward tensor([0.7000]), enemy health [12, 8.0], model health [7.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 616 ended with reward tensor([-1.3000]), enemy health [12, 3.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 1
draw!
Slay and Secure Victory Condition
enemy won!
Iteration 617 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 618 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 619 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 620 ended with reward tensor([-1.]), enemy health [12, 9.0], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 621 ended with reward tensor([-0.5000]), enemy health [12, 9.0], model health [12.0, 10.0], model VP 0, enemy VP 0, victory condition 1
Iteration 622 ended with reward tensor([-0.5000]), enemy health [12, 9.0], model health [10.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 623 ended with reward tensor([0.7000]), enemy health [12, 7.0], model health [10.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 624 ended with reward tensor([-1]), enemy health [12, 7.0], model health [10.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 625 ended with reward tensor([-1.5000]), enemy health [12, 7.0], model health [10.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 626 ended with reward tensor([-4.]), enemy health [12, 7.0], model health [7.0, 0], model VP 0, enemy VP 0, victory condition 1
draw!
Slay and Secure Victory Condition
enemy won!
Iteration 627 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 628 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 629 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 630 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 631 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 632 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 633 ended with reward tensor([0.7000]), enemy health [12, 8.0], model health [11.0, 11.0], model VP 0, enemy VP 0, victory condition 1
Iteration 634 ended with reward tensor([-0.5000]), enemy health [12, 8.0], model health [8.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 635 ended with reward tensor([-1.5000]), enemy health [12, 8.0], model health [8.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 636 ended with reward tensor([-2.]), enemy health [8.0, 8.0], model health [8.0, 0], model VP 0, enemy VP 0, victory condition 1
draw!
Slay and Secure Victory Condition
enemy won!
Iteration 637 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 638 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 639 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 640 ended with reward tensor([0.7000]), enemy health [6.0, 12], model health [12, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 641 ended with reward tensor([0]), enemy health [6.0, 12], model health [12, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 642 ended with reward tensor([0.7000]), enemy health [2.0, 12], model health [7.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 643 ended with reward tensor([1.]), enemy health [0.0, 12], model health [3.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 644 ended with reward tensor([0.5000]), enemy health [0.0, 12], model health [3.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 645 ended with reward tensor([-3.5000]), enemy health [0.0, 12], model health [3.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 646 ended with reward tensor([-1.3000]), enemy health [0.0, 5.0], model health [3.0, 1.0], model VP 0, enemy VP 0, victory condition 2
draw!
Ancient Relic Victory Condition
enemy won!
Iteration 647 ended with reward tensor([1.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 648 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 649 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 650 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 651 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 6.0], model VP 0, enemy VP 0, victory condition 1
Iteration 652 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 653 ended with reward tensor([-1]), enemy health [12, 12], model health [9.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 654 ended with reward tensor([-4]), enemy health [12, 12], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
enemy won!
Major Victory
enemy won!
Iteration 655 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 656 ended with reward tensor([0.]), enemy health [10.0, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 657 ended with reward tensor([0.7000]), enemy health [10.0, 10.0], model health [12, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 658 ended with reward tensor([-1.]), enemy health [10.0, 10.0], model health [12, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 659 ended with reward tensor([0.5000]), enemy health [5.0, 10.0], model health [12, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 660 ended with reward tensor([-0.5000]), enemy health [5.0, 10.0], model health [10.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 661 ended with reward tensor([-1.]), enemy health [2.0, 10.0], model health [4.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 662 ended with reward tensor([-0.8000]), enemy health [2.0, 7.0], model health [3.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 663 ended with reward tensor([-4]), enemy health [2.0, 7.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
enemy won!
Major Victory
enemy won!
Iteration 664 ended with reward tensor([0.7000]), enemy health [8.0, 12], model health [12, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 665 ended with reward tensor([0.7000]), enemy health [1.0, 12], model health [12, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 666 ended with reward tensor([-1.5000]), enemy health [1.0, 12], model health [12, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 667 ended with reward tensor([-0.5000]), enemy health [1.0, 12], model health [12, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 668 ended with reward tensor([-0.5000]), enemy health [0.0, 12], model health [11.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 669 ended with reward tensor([-0.8000]), enemy health [0.0, 11.0], model health [7.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 670 ended with reward tensor([-1]), enemy health [0.0, 11.0], model health [3.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 671 ended with reward tensor([-4]), enemy health [0.0, 11.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 672 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 673 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 674 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 675 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 676 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 677 ended with reward tensor([-0.5000]), enemy health [12, 8.0], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 678 ended with reward tensor([0.7000]), enemy health [7.0, 8.0], model health [12, 6.0], model VP 0, enemy VP 0, victory condition 1
Iteration 679 ended with reward tensor([0.7000]), enemy health [7.0, 4.0], model health [12, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 680 ended with reward tensor([-0.5000]), enemy health [7.0, 4.0], model health [5.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 681 ended with reward tensor([-2]), enemy health [7.0, 4.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
draw!
Slay and Secure Victory Condition
enemy won!
Iteration 682 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 683 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 684 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 685 ended with reward tensor([0.7000]), enemy health [7.0, 7.0], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 686 ended with reward tensor([0.7000]), enemy health [7.0, 4.0], model health [10.0, 8.0], model VP 0, enemy VP 0, victory condition 3
Iteration 687 ended with reward tensor([-0.5000]), enemy health [7.0, 4.0], model health [8.0, 5.0], model VP 0, enemy VP 0, victory condition 3
Iteration 688 ended with reward tensor([-1.5000]), enemy health [7.0, 4.0], model health [5.0, 0.0], model VP 0, enemy VP 0, victory condition 3
Iteration 689 ended with reward tensor([0.]), enemy health [0.0, 4.0], model health [3.0, 0.0], model VP 0, enemy VP 0, victory condition 3
Iteration 690 ended with reward tensor([-1]), enemy health [0.0, 4.0], model health [3.0, 0.0], model VP 0, enemy VP 0, victory condition 3
Iteration 691 ended with reward tensor([-4]), enemy health [0.0, 4.0], model health [3.0, 0.0], model VP 0, enemy VP 0, victory condition 3
draw!
Domination Victory Condition
enemy won!
Iteration 692 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 693 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 694 ended with reward tensor([0.7000]), enemy health [7.0, 12], model health [12, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 695 ended with reward tensor([0.7000]), enemy health [4.0, 12], model health [12, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 696 ended with reward tensor([0.7000]), enemy health [2.0, 12], model health [12, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 697 ended with reward tensor([-2.]), enemy health [2.0, 12], model health [12, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 698 ended with reward tensor([-1.5000]), enemy health [2.0, 12], model health [12, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 699 ended with reward tensor([-1.5000]), enemy health [2.0, 12], model health [5.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 700 ended with reward tensor([-4.5000]), enemy health [2.0, 12], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
enemy won!
Major Victory
enemy won!
Iteration 701 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 702 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 703 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 704 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 705 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 706 ended with reward tensor([0.7000]), enemy health [7.0, 9.0], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 707 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [9.0, 10.0], model VP 0, enemy VP 0, victory condition 3
Iteration 708 ended with reward tensor([1.]), enemy health [0, 9.0], model health [5.0, 8.0], model VP 0, enemy VP 0, victory condition 3
Iteration 709 ended with reward tensor([0.5000]), enemy health [0, 9.0], model health [5.0, 2.0], model VP 0, enemy VP 0, victory condition 3
Iteration 710 ended with reward tensor([-2.]), enemy health [0, 9.0], model health [5.0, 0], model VP 0, enemy VP 0, victory condition 3
draw!
Domination Victory Condition
enemy won!
Iteration 711 ended with reward tensor([0.7000]), enemy health [12, 7.0], model health [12, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 712 ended with reward tensor([1.2000]), enemy health [12, 4.0], model health [10.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 713 ended with reward tensor([0.7000]), enemy health [12, 1.0], model health [2.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 714 ended with reward tensor([0.7000]), enemy health [7.0, 1.0], model health [0, 6.0], model VP 0, enemy VP 0, victory condition 2
Iteration 715 ended with reward tensor([-4]), enemy health [7.0, 1.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 716 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 717 ended with reward tensor([0.7000]), enemy health [12, 7.0], model health [9.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 718 ended with reward tensor([0.7000]), enemy health [7.0, 5.0], model health [2.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 719 ended with reward tensor([0.7000]), enemy health [7.0, 3.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 720 ended with reward tensor([1.]), enemy health [7.0, 0.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 721 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 3
Iteration 722 ended with reward tensor([3.]), enemy health [0.0, 0.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 3
model won!
Major Victory
model won!
Iteration 723 ended with reward tensor([1.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 724 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 725 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 726 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 727 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 728 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 729 ended with reward tensor([0.7000]), enemy health [9.0, 12], model health [12, 9.0], model VP 0, enemy VP 0, victory condition 3
Iteration 730 ended with reward tensor([0.7000]), enemy health [6.0, 12], model health [12, 8.0], model VP 0, enemy VP 0, victory condition 3
Iteration 731 ended with reward tensor([0.7000]), enemy health [6.0, 12], model health [12, 4.0], model VP 0, enemy VP 0, victory condition 3
Iteration 732 ended with reward tensor([-3.5000]), enemy health [6.0, 12], model health [12, 0.0], model VP 0, enemy VP 0, victory condition 3
draw!
Domination Victory Condition
enemy won!
Iteration 733 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 734 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 735 ended with reward tensor([0.7000]), enemy health [12, 10.0], model health [11.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 736 ended with reward tensor([0.7000]), enemy health [12, 5.0], model health [11.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 737 ended with reward tensor([1.]), enemy health [7.0, 0.0], model health [10.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 738 ended with reward tensor([0.7000]), enemy health [5.0, 0], model health [10.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 739 ended with reward tensor([0.7000]), enemy health [1.0, 0], model health [10.0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 740 ended with reward tensor([3.]), enemy health [0, 0], model health [10.0, 1.0], model VP 0, enemy VP 0, victory condition 1
model won!
Major Victory
model won!
Iteration 741 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 742 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 743 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 744 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 745 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 746 ended with reward tensor([0.7000]), enemy health [9.0, 12], model health [12, 8.0], model VP 0, enemy VP 0, victory condition 3
Iteration 747 ended with reward tensor([-1]), enemy health [9.0, 12], model health [6.0, 0.0], model VP 0, enemy VP 0, victory condition 3
Iteration 748 ended with reward tensor([-2]), enemy health [9.0, 12], model health [4.0, 0.0], model VP 0, enemy VP 0, victory condition 3
Iteration 749 ended with reward tensor([-4]), enemy health [9.0, 12], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 3
enemy won!
Major Victory
enemy won!
Iteration 750 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 751 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 752 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 753 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 754 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 755 ended with reward tensor([0.7000]), enemy health [10.0, 12], model health [8.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 756 ended with reward tensor([0.7000]), enemy health [6.0, 12], model health [7.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 757 ended with reward tensor([0.7000]), enemy health [2.0, 12], model health [3.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 758 ended with reward tensor([-0.5000]), enemy health [2.0, 12], model health [0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 759 ended with reward tensor([-1.3000]), enemy health [2.0, 7.0], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 1
draw!
Slay and Secure Victory Condition
enemy won!
Iteration 760 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 761 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 762 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 763 ended with reward tensor([0.7000]), enemy health [12, 6.0], model health [2.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 764 ended with reward tensor([0.7000]), enemy health [12, 1.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 765 ended with reward tensor([1.]), enemy health [12, 0.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 766 ended with reward tensor([0.7000]), enemy health [9.0, 0.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 767 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 768 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 769 ended with reward tensor([-2.5000]), enemy health [2.0, 0.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 1
draw!
Slay and Secure Victory Condition
enemy won!
Iteration 770 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 771 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 772 ended with reward tensor([-1]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 773 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 774 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 775 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 776 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 777 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 778 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 779 ended with reward tensor([-1.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
draw!
Ancient Relic Victory Condition
enemy won!
Iteration 780 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 781 ended with reward tensor([-4.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 782 ended with reward tensor([0.7000]), enemy health [12, 10.0], model health [12, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 783 ended with reward tensor([0.7000]), enemy health [12, 4.0], model health [12, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 784 ended with reward tensor([0.]), enemy health [12, 0.0], model health [12, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 785 ended with reward tensor([0.]), enemy health [12, 0.0], model health [8.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 786 ended with reward tensor([-0.5000]), enemy health [12, 0.0], model health [6.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 787 ended with reward tensor([-1.5000]), enemy health [12, 0.0], model health [4.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 788 ended with reward tensor([0.]), enemy health [12, 0.0], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 789 ended with reward tensor([-3.]), enemy health [12, 0.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
enemy won!
Major Victory
enemy won!
Iteration 790 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 791 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 792 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [10.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 793 ended with reward tensor([0.7000]), enemy health [12, 6.0], model health [6.0, 9.0], model VP 0, enemy VP 0, victory condition 3
Iteration 794 ended with reward tensor([0.7000]), enemy health [12, 5.0], model health [3.0, 1.0], model VP 0, enemy VP 0, victory condition 3
Iteration 795 ended with reward tensor([-4]), enemy health [12, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 3
enemy won!
Major Victory
enemy won!
Iteration 796 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 797 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 798 ended with reward tensor([1.5000]), enemy health [4.0, 8.0], model health [10.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 799 ended with reward tensor([0]), enemy health [4.0, 8.0], model health [6.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 800 ended with reward tensor([-0.5000]), enemy health [4.0, 8.0], model health [0.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 801 ended with reward tensor([0.7000]), enemy health [4.0, 2.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 3
Iteration 802 ended with reward tensor([-0.5000]), enemy health [4.0, 2.0], model health [0.0, 6.0], model VP 0, enemy VP 0, victory condition 3
Iteration 803 ended with reward tensor([1.]), enemy health [0, 2.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 3
Iteration 804 ended with reward tensor([-4]), enemy health [0, 2.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 3
enemy won!
Major Victory
enemy won!
Iteration 805 ended with reward tensor([-3.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 806 ended with reward tensor([0.7000]), enemy health [6.0, 6.0], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 807 ended with reward tensor([-0.5000]), enemy health [6.0, 6.0], model health [12, 10.0], model VP 0, enemy VP 0, victory condition 3
Iteration 808 ended with reward tensor([0.7000]), enemy health [4.0, 2.0], model health [12, 6.0], model VP 0, enemy VP 0, victory condition 3
Iteration 809 ended with reward tensor([1.]), enemy health [4.0, 0], model health [10.0, 6.0], model VP 0, enemy VP 0, victory condition 3
Iteration 810 ended with reward tensor([3.]), enemy health [0.0, 0], model health [10.0, 3.0], model VP 0, enemy VP 0, victory condition 3
model won!
Major Victory
model won!
Iteration 811 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 812 ended with reward tensor([-5.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 813 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 814 ended with reward tensor([0.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 815 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 816 ended with reward tensor([0.7000]), enemy health [12, 8.0], model health [3.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 817 ended with reward tensor([0.7000]), enemy health [12, 4.0], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 818 ended with reward tensor([1.]), enemy health [12, 0], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 819 ended with reward tensor([0.7000]), enemy health [9.0, 0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 820 ended with reward tensor([-4]), enemy health [9.0, 0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
enemy won!
Major Victory
enemy won!
Iteration 821 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 822 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 823 ended with reward tensor([0.7000]), enemy health [8.0, 12], model health [8.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 824 ended with reward tensor([0]), enemy health [8.0, 12], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 825 ended with reward tensor([0.7000]), enemy health [5.0, 12], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 826 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 827 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 828 ended with reward tensor([-0.5000]), enemy health [1.0, 7.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 829 ended with reward tensor([0.7000]), enemy health [1.0, 3.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 830 ended with reward tensor([-4]), enemy health [1.0, 3.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 831 ended with reward tensor([1.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 832 ended with reward tensor([-0.5000]), enemy health [12, 12], model health [12, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 833 ended with reward tensor([0.7000]), enemy health [12, 10.0], model health [12, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 834 ended with reward tensor([-1]), enemy health [12, 10.0], model health [12, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 835 ended with reward tensor([-2.5000]), enemy health [12, 10.0], model health [12, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 836 ended with reward tensor([-1]), enemy health [12, 10.0], model health [8.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 837 ended with reward tensor([0.]), enemy health [12, 10.0], model health [3.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 838 ended with reward tensor([-4]), enemy health [12, 10.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 839 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 840 ended with reward tensor([1.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 841 ended with reward tensor([1.5000]), enemy health [11.0, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 842 ended with reward tensor([0.7000]), enemy health [9.0, 8.0], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 843 ended with reward tensor([0.7000]), enemy health [9.0, 7.0], model health [12, 8.0], model VP 0, enemy VP 0, victory condition 3
Iteration 844 ended with reward tensor([1.]), enemy health [9.0, 0.0], model health [12, 1.0], model VP 0, enemy VP 0, victory condition 3
Iteration 845 ended with reward tensor([0.7000]), enemy health [7.0, 0.0], model health [9.0, 1.0], model VP 0, enemy VP 0, victory condition 3
Iteration 846 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [4.0, 1.0], model VP 0, enemy VP 0, victory condition 3
Iteration 847 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 3
Iteration 848 ended with reward tensor([-4.5000]), enemy health [3.0, 0.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 3
enemy won!
Major Victory
enemy won!
Iteration 849 ended with reward tensor([1.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 850 ended with reward tensor([1.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 851 ended with reward tensor([0.7000]), enemy health [12, 5.0], model health [12, 9.0], model VP 0, enemy VP 0, victory condition 3
Iteration 852 ended with reward tensor([1.]), enemy health [9.0, 0.0], model health [12, 3.0], model VP 0, enemy VP 0, victory condition 3
Iteration 853 ended with reward tensor([0.]), enemy health [9.0, 0], model health [12, 0.0], model VP 0, enemy VP 0, victory condition 3
Iteration 854 ended with reward tensor([0.5000]), enemy health [4.0, 0], model health [12, 0.0], model VP 0, enemy VP 0, victory condition 3
Iteration 855 ended with reward tensor([-0.5000]), enemy health [4.0, 0], model health [12, 0], model VP 0, enemy VP 0, victory condition 3
Iteration 856 ended with reward tensor([0.]), enemy health [4.0, 0], model health [12, 0], model VP 0, enemy VP 0, victory condition 3
Iteration 857 ended with reward tensor([0.5000]), enemy health [2.0, 0], model health [12, 0], model VP 0, enemy VP 0, victory condition 3
Iteration 858 ended with reward tensor([-2.5000]), enemy health [2.0, 0.0], model health [12, 0], model VP 0, enemy VP 0, victory condition 3
draw!
Domination Victory Condition
enemy won!
Iteration 859 ended with reward tensor([0.5000]), enemy health [12, 11.0], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 860 ended with reward tensor([0.7000]), enemy health [8.0, 7.0], model health [9.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 861 ended with reward tensor([-0.5000]), enemy health [8.0, 7.0], model health [6.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 862 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 863 ended with reward tensor([-4]), enemy health [5.0, 7.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
enemy won!
Major Victory
enemy won!
Iteration 864 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 865 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 866 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 867 ended with reward tensor([0.7000]), enemy health [11.0, 12], model health [12, 11.0], model VP 0, enemy VP 0, victory condition 2
Iteration 868 ended with reward tensor([0.7000]), enemy health [11.0, 11.0], model health [9.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 869 ended with reward tensor([0.7000]), enemy health [11.0, 7.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 870 ended with reward tensor([-0.5000]), enemy health [11.0, 7.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 871 ended with reward tensor([0.7000]), enemy health [11.0, 3.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 872 ended with reward tensor([-4]), enemy health [11.0, 3.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 873 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 874 ended with reward tensor([-4.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 875 ended with reward tensor([0.7000]), enemy health [7.0, 12], model health [6.0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 876 ended with reward tensor([-0.5000]), enemy health [7.0, 12], model health [1.0, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 877 ended with reward tensor([0.7000]), enemy health [7.0, 11.0], model health [0, 10.0], model VP 0, enemy VP 0, victory condition 2
Iteration 878 ended with reward tensor([0.]), enemy health [7.0, 7.0], model health [0, 10.0], model VP 0, enemy VP 0, victory condition 2
Iteration 879 ended with reward tensor([0.7000]), enemy health [7.0, 5.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 880 ended with reward tensor([0.7000]), enemy health [7.0, 2.0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 2
Iteration 881 ended with reward tensor([-3.]), enemy health [7.0, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
enemy won!
Major Victory
enemy won!
Iteration 882 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 883 ended with reward tensor([0]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 884 ended with reward tensor([1.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 885 ended with reward tensor([0.7000]), enemy health [12, 11.0], model health [7.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 886 ended with reward tensor([0.7000]), enemy health [12, 6.0], model health [3.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 887 ended with reward tensor([0.7000]), enemy health [12, 3.0], model health [2.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 888 ended with reward tensor([0.7000]), enemy health [8.0, 3.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 889 ended with reward tensor([1.]), enemy health [8.0, 0], model health [0.0, 12], model VP 0, enemy VP 0, victory condition 3
Iteration 890 ended with reward tensor([0.7000]), enemy health [2.0, 0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 3
Iteration 891 ended with reward tensor([-1.3000]), enemy health [2.0, 0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 3
draw!
Domination Victory Condition
enemy won!
Iteration 892 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 893 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 894 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 895 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 896 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 897 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 898 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 899 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 900 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 901 ended with reward tensor([-1.]), enemy health [9.0, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
draw!
Ancient Relic Victory Condition
enemy won!
Iteration 902 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 903 ended with reward tensor([-5.]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 904 ended with reward tensor([0.7000]), enemy health [12, 12], model health [10.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 905 ended with reward tensor([0.7000]), enemy health [12, 6.0], model health [7.0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 906 ended with reward tensor([0.7000]), enemy health [12, 4.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 907 ended with reward tensor([0.7000]), enemy health [5.0, 4.0], model health [0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 908 ended with reward tensor([1.]), enemy health [5.0, 0], model health [0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 909 ended with reward tensor([0.]), enemy health [1.0, 0], model health [0, 12], model VP 0, enemy VP 0, victory condition 1
Iteration 910 ended with reward tensor([3.]), enemy health [0, 0], model health [0, 12], model VP 0, enemy VP 0, victory condition 1
model won!
Major Victory
model won!
Iteration 911 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 912 ended with reward tensor([0.5000]), enemy health [12, 12], model health [12, 12], model VP 0, enemy VP 0, victory condition 2
Iteration 913 ended with reward tensor([0.7000]), enemy health [9.0, 7.0], model health [12, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 914 ended with reward tensor([0.7000]), enemy health [9.0, 1.0], model health [9.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 915 ended with reward tensor([1.]), enemy health [9.0, 0.0], model health [7.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 916 ended with reward tensor([1.5000]), enemy health [2.0, 0.0], model health [7.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 917 ended with reward tensor([1.]), enemy health [2.0, 0], model health [7.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 918 ended with reward tensor([3.]), enemy health [0, 0], model health [7.0, 4.0], model VP 0, enemy VP 0, victory condition 2
model won!
Major Victory
model won!
