Model units:
Name: Apothecary, Army Type: Space_Marine
Name: Eliminator Squad, Army Type: Space_Marine
Enemy units:
Name: Apothecary, Army Type: Space_Marine
Name: Eliminator Squad, Army Type: Space_Marine
Number of Lifetimes ran: 100

Iteration 0 ended with reward tensor([0.9000]), enemy health [4, 5.0], model health [1.0, 2.0], model VP 0, enemy VP 1, victory condition 2
Iteration 1 ended with reward tensor([-0.3000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 2, victory condition 2
Iteration 2 ended with reward tensor([-3.5000]), enemy health [0, 5.0], model health [0, 0], model VP 0, enemy VP 4, victory condition 2
Major Victory
enemy won!
Iteration 3 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 2, victory condition 1
Iteration 4 ended with reward tensor([-4]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
enemy won!
Iteration 5 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 6 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 4, victory condition 2
Iteration 7 ended with reward tensor([-0.3000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 5, victory condition 2
Iteration 8 ended with reward tensor([-1.]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 6, victory condition 2
Iteration 9 ended with reward tensor([-4]), enemy health [0, 5.0], model health [0, 0], model VP 0, enemy VP 7, victory condition 2
Major Victory
enemy won!
Iteration 10 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 11 ended with reward tensor([-1]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 12 ended with reward tensor([-1.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 13 ended with reward tensor([-0.8000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 1
Iteration 14 ended with reward tensor([-2]), enemy health [4, 5.0], model health [0, 1.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 15 ended with reward tensor([1.2000]), enemy health [4, 5.0], model health [4, 2.0], model VP 1, enemy VP 1, victory condition 2
Iteration 16 ended with reward tensor([0.2000]), enemy health [4, 0], model health [4.0, 2.0], model VP 2, enemy VP 3, victory condition 2
Iteration 17 ended with reward tensor([-0.5000]), enemy health [1.0, 0], model health [1.0, 2.0], model VP 3, enemy VP 5, victory condition 2
Iteration 18 ended with reward tensor([-0.5000]), enemy health [1.0, 0], model health [1.0, 2.0], model VP 4, enemy VP 6, victory condition 2
Iteration 19 ended with reward tensor([1.]), enemy health [1.0, 0], model health [1.0, 2.0], model VP 12, enemy VP 7, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 20 ended with reward tensor([-0.8000]), enemy health [4, 5.0], model health [4, 0], model VP 2, enemy VP 1, victory condition 1
Iteration 21 ended with reward tensor([-4]), enemy health [4, 5.0], model health [0, 0], model VP 4, enemy VP 2, victory condition 1
Major Victory
enemy won!
Iteration 22 ended with reward tensor([-4.]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 1, victory condition 1
Iteration 23 ended with reward tensor([-3.5000]), enemy health [4, 8], model health [4, 8], model VP 4, enemy VP 2, victory condition 1
Iteration 24 ended with reward tensor([-1.]), enemy health [4, 8], model health [0, 8], model VP 5, enemy VP 4, victory condition 1
Iteration 25 ended with reward tensor([-5.5000]), enemy health [4, 8], model health [0, 0], model VP 6, enemy VP 5, victory condition 1
Major Victory
enemy won!
Iteration 26 ended with reward tensor([-1]), enemy health [4, 8], model health [0.0, 8], model VP 1, enemy VP 1, victory condition 1
Iteration 27 ended with reward tensor([-1.]), enemy health [4, 8], model health [0.0, 5.0], model VP 2, enemy VP 2, victory condition 1
Iteration 28 ended with reward tensor([0.7000]), enemy health [3.0, 8], model health [0, 5.0], model VP 3, enemy VP 3, victory condition 1
Iteration 29 ended with reward tensor([-0.5000]), enemy health [3.0, 8], model health [0, 5.0], model VP 4, enemy VP 4, victory condition 1
Iteration 30 ended with reward tensor([-2.5000]), enemy health [3.0, 8], model health [0, 0.0], model VP 4, enemy VP 5, victory condition 1
Major Victory
enemy won!
Iteration 31 ended with reward tensor([-0.8000]), enemy health [4, 5.0], model health [0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 32 ended with reward tensor([-4]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
enemy won!
Iteration 33 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [4, 0.0], model VP 0, enemy VP 3, victory condition 2
Iteration 34 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [1.0, 0.0], model VP 0, enemy VP 6, victory condition 2
Iteration 35 ended with reward tensor([-4.5000]), enemy health [4, 8], model health [0, 0.0], model VP 0, enemy VP 9, victory condition 2
Major Victory
enemy won!
Iteration 36 ended with reward tensor([0.7000]), enemy health [4, 2.0], model health [4, 5.0], model VP 0, enemy VP 3, victory condition 2
Iteration 37 ended with reward tensor([0.2000]), enemy health [4, 0], model health [1.0, 2.0], model VP 0, enemy VP 7, victory condition 2
Iteration 38 ended with reward tensor([-1.5000]), enemy health [4, 0], model health [1.0, 0], model VP 0, enemy VP 11, victory condition 2
Iteration 39 ended with reward tensor([-4]), enemy health [4, 0], model health [0, 0], model VP 0, enemy VP 14, victory condition 2
Major Victory
enemy won!
Iteration 40 ended with reward tensor([-1]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 3, victory condition 2
Iteration 41 ended with reward tensor([-1]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 6, victory condition 2
Iteration 42 ended with reward tensor([-1]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 10, victory condition 2
Iteration 43 ended with reward tensor([-1]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 14, victory condition 2
Iteration 44 ended with reward tensor([-2.8000]), enemy health [4, 5.0], model health [0, 5.0], model VP 0, enemy VP 24, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 45 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 4, victory condition 1
Iteration 46 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 8, victory condition 1
Iteration 47 ended with reward tensor([0.2000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 11, victory condition 1
Iteration 48 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [4, 5.0], model VP 0, enemy VP 14, victory condition 1
Iteration 49 ended with reward tensor([-1.3000]), enemy health [0, 5.0], model health [4, 2.0], model VP 0, enemy VP 3, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 50 ended with reward tensor([-0.3000]), enemy health [4, 0], model health [4, 2.0], model VP 1, enemy VP 3, victory condition 2
Iteration 51 ended with reward tensor([0.9000]), enemy health [1.0, 0], model health [4, 2.0], model VP 3, enemy VP 5, victory condition 2
Iteration 52 ended with reward tensor([-3.3000]), enemy health [1.0, 0], model health [4, 0], model VP 5, enemy VP 7, victory condition 2
Iteration 53 ended with reward tensor([-3.]), enemy health [1.0, 0], model health [3.0, 0], model VP 7, enemy VP 9, victory condition 2
Iteration 54 ended with reward tensor([1]), enemy health [1.0, 0], model health [3.0, 0], model VP 15, enemy VP 11, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 55 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [4, 8], model VP 2, enemy VP 2, victory condition 2
Iteration 56 ended with reward tensor([0.9000]), enemy health [1.0, 5.0], model health [4, 8], model VP 4, enemy VP 4, victory condition 2
Iteration 57 ended with reward tensor([-0.8000]), enemy health [1.0, 2.0], model health [0, 8], model VP 6, enemy VP 6, victory condition 2
Iteration 58 ended with reward tensor([1.]), enemy health [0, 2.0], model health [0, 8], model VP 8, enemy VP 8, victory condition 2
Iteration 59 ended with reward tensor([1.5000]), enemy health [0, 2.0], model health [0.0, 8], model VP 16, enemy VP 10, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 60 ended with reward tensor([-2.8000]), enemy health [4, 5.0], model health [4.0, 8], model VP 1, enemy VP 2, victory condition 2
Iteration 61 ended with reward tensor([1.4000]), enemy health [4, 0.0], model health [4.0, 8], model VP 2, enemy VP 4, victory condition 2
Iteration 62 ended with reward tensor([0.]), enemy health [4, 0.0], model health [4.0, 8], model VP 3, enemy VP 6, victory condition 2
Iteration 63 ended with reward tensor([-0.5000]), enemy health [4, 0.0], model health [1.0, 8], model VP 5, enemy VP 8, victory condition 2
Iteration 64 ended with reward tensor([1.5000]), enemy health [4, 0.0], model health [0.0, 8], model VP 13, enemy VP 10, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 65 ended with reward tensor([-3.]), enemy health [4, 8], model health [0, 8], model VP 2, enemy VP 2, victory condition 1
Iteration 66 ended with reward tensor([-0.8000]), enemy health [4, 2.0], model health [0, 8], model VP 3, enemy VP 4, victory condition 1
Iteration 67 ended with reward tensor([-3.5000]), enemy health [4, 2.0], model health [0, 5.0], model VP 4, enemy VP 6, victory condition 1
Iteration 68 ended with reward tensor([-0.3000]), enemy health [4, 0], model health [0, 5.0], model VP 5, enemy VP 8, victory condition 1
Iteration 69 ended with reward tensor([-5.]), enemy health [4, 0], model health [0, 5.0], model VP 1, enemy VP 2, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 70 ended with reward tensor([-0.8000]), enemy health [1.0, 8], model health [4, 0], model VP 1, enemy VP 2, victory condition 2
Iteration 71 ended with reward tensor([-4]), enemy health [1.0, 8], model health [0, 0], model VP 2, enemy VP 4, victory condition 2
Major Victory
enemy won!
Iteration 72 ended with reward tensor([-0.8000]), enemy health [4, 0], model health [0, 8], model VP 1, enemy VP 2, victory condition 1
Iteration 73 ended with reward tensor([1.2000]), enemy health [0, 0], model health [0, 8], model VP 3, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 74 ended with reward tensor([-0.8000]), enemy health [0, 8], model health [0.0, 5.0], model VP 2, enemy VP 2, victory condition 1
Iteration 75 ended with reward tensor([-3.5000]), enemy health [0, 8], model health [0.0, 5.0], model VP 4, enemy VP 4, victory condition 1
Iteration 76 ended with reward tensor([-4]), enemy health [0, 8], model health [0.0, 0], model VP 6, enemy VP 6, victory condition 1
Major Victory
enemy won!
Iteration 77 ended with reward tensor([-4.]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 2, victory condition 2
Iteration 78 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 4, enemy VP 4, victory condition 2
Iteration 79 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 2.0], model VP 5, enemy VP 6, victory condition 2
Iteration 80 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [4, 2.0], model VP 7, enemy VP 8, victory condition 2
Iteration 81 ended with reward tensor([1.]), enemy health [0, 8], model health [0, 2.0], model VP 15, enemy VP 10, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 82 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 2, victory condition 2
Iteration 83 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 4, enemy VP 4, victory condition 2
Iteration 84 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 6, enemy VP 6, victory condition 2
Iteration 85 ended with reward tensor([0.4000]), enemy health [4, 2.0], model health [4.0, 5.0], model VP 8, enemy VP 8, victory condition 2
Iteration 86 ended with reward tensor([1.2000]), enemy health [0, 2.0], model health [0, 5.0], model VP 16, enemy VP 10, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 87 ended with reward tensor([-3.1000]), enemy health [0, 8], model health [4, 2.0], model VP 2, enemy VP 2, victory condition 1
Iteration 88 ended with reward tensor([-0.3000]), enemy health [0, 8], model health [4, 0], model VP 4, enemy VP 4, victory condition 1
Iteration 89 ended with reward tensor([-1.]), enemy health [0, 8], model health [1.0, 0], model VP 6, enemy VP 6, victory condition 1
Iteration 90 ended with reward tensor([-4]), enemy health [0, 8], model health [0, 0], model VP 8, enemy VP 8, victory condition 1
Major Victory
enemy won!
Iteration 91 ended with reward tensor([0.9000]), enemy health [4, 8.0], model health [4, 2.0], model VP 2, enemy VP 2, victory condition 2
Iteration 92 ended with reward tensor([-1.]), enemy health [4, 8.0], model health [4, 2.0], model VP 3, enemy VP 4, victory condition 2
Iteration 93 ended with reward tensor([-0.8000]), enemy health [4, 8.0], model health [4, 0.0], model VP 4, enemy VP 6, victory condition 2
Iteration 94 ended with reward tensor([-4]), enemy health [4, 8.0], model health [0, 0.0], model VP 5, enemy VP 8, victory condition 2
Major Victory
enemy won!
Iteration 95 ended with reward tensor([-0.3000]), enemy health [4, 5.0], model health [0, 8], model VP 1, enemy VP 2, victory condition 1
Iteration 96 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0, 8], model VP 2, enemy VP 4, victory condition 1
Iteration 97 ended with reward tensor([-1.]), enemy health [4, 5.0], model health [0, 5.0], model VP 3, enemy VP 6, victory condition 1
Iteration 98 ended with reward tensor([-4]), enemy health [4, 5.0], model health [0, 0], model VP 4, enemy VP 8, victory condition 1
Major Victory
enemy won!
Iteration 99 ended with reward tensor([1.9000]), enemy health [4, 2.0], model health [1.0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 100 ended with reward tensor([-0.3000]), enemy health [4, 0], model health [1.0, 0], model VP 0, enemy VP 4, victory condition 2
Iteration 101 ended with reward tensor([-4]), enemy health [4, 0], model health [0.0, 0], model VP 0, enemy VP 6, victory condition 2
Major Victory
enemy won!
Iteration 102 ended with reward tensor([-0.3000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 103 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 4, victory condition 2
Iteration 104 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0, 1.0], model VP 1, enemy VP 6, victory condition 2
Iteration 105 ended with reward tensor([-0.5000]), enemy health [0, 4.0], model health [0, 1.0], model VP 1, enemy VP 8, victory condition 2
Iteration 106 ended with reward tensor([2.2000]), enemy health [0, 0], model health [0, 1.0], model VP 2, enemy VP 10, victory condition 2
Major Victory
model won!
Iteration 107 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [1.0, 8], model VP 1, enemy VP 2, victory condition 2
Iteration 108 ended with reward tensor([-3.6000]), enemy health [1.0, 8], model health [1.0, 8], model VP 3, enemy VP 4, victory condition 2
Iteration 109 ended with reward tensor([-1.]), enemy health [1.0, 8], model health [1.0, 8], model VP 5, enemy VP 6, victory condition 2
Iteration 110 ended with reward tensor([-1.]), enemy health [1.0, 8], model health [1.0, 8], model VP 6, enemy VP 8, victory condition 2
Iteration 111 ended with reward tensor([2.9000]), enemy health [0, 8], model health [1.0, 5.0], model VP 13, enemy VP 10, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 112 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 1, enemy VP 2, victory condition 1
Iteration 113 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 4, victory condition 1
Iteration 114 ended with reward tensor([-1.]), enemy health [4, 8], model health [4, 5.0], model VP 3, enemy VP 6, victory condition 1
Iteration 115 ended with reward tensor([-0.8000]), enemy health [4, 8], model health [0.0, 5.0], model VP 4, enemy VP 8, victory condition 1
Iteration 116 ended with reward tensor([-4]), enemy health [4, 8], model health [0.0, 0.0], model VP 5, enemy VP 10, victory condition 1
Major Victory
enemy won!
Iteration 117 ended with reward tensor([-3.5000]), enemy health [4, 8], model health [4, 8], model VP 1, enemy VP 2, victory condition 1
Iteration 118 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 4, victory condition 1
Iteration 119 ended with reward tensor([0.4000]), enemy health [4, 8], model health [4, 5.0], model VP 3, enemy VP 6, victory condition 1
Iteration 120 ended with reward tensor([-3.1000]), enemy health [4, 0], model health [4.0, 2.0], model VP 4, enemy VP 8, victory condition 1
Iteration 121 ended with reward tensor([-3.5000]), enemy health [4, 0], model health [4.0, 0], model VP 1, enemy VP 2, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 122 ended with reward tensor([0.9000]), enemy health [4, 8], model health [4, 8.0], model VP 1, enemy VP 2, victory condition 2
Iteration 123 ended with reward tensor([-0.3000]), enemy health [1.0, 8.0], model health [4, 5.0], model VP 2, enemy VP 4, victory condition 2
Iteration 124 ended with reward tensor([0.4000]), enemy health [1.0, 5.0], model health [1.0, 5.0], model VP 2, enemy VP 7, victory condition 2
Iteration 125 ended with reward tensor([0.2000]), enemy health [1.0, 5.0], model health [1.0, 2.0], model VP 2, enemy VP 9, victory condition 2
Iteration 126 ended with reward tensor([-5.5000]), enemy health [1.0, 5.0], model health [1.0, 0.0], model VP 3, enemy VP 18, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 127 ended with reward tensor([-2.5000]), enemy health [4, 8], model health [0, 8], model VP 1, enemy VP 3, victory condition 1
Iteration 128 ended with reward tensor([-0.8000]), enemy health [1.0, 8], model health [0, 2.0], model VP 2, enemy VP 6, victory condition 1
Iteration 129 ended with reward tensor([-4]), enemy health [1.0, 8], model health [0, 0], model VP 2, enemy VP 9, victory condition 1
Major Victory
enemy won!
Iteration 130 ended with reward tensor([-3.]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 131 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 6, victory condition 1
Iteration 132 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 9, victory condition 1
Iteration 133 ended with reward tensor([-4]), enemy health [4, 8], model health [0, 0.0], model VP 0, enemy VP 12, victory condition 1
Major Victory
enemy won!
Iteration 134 ended with reward tensor([0.7000]), enemy health [1.0, 8], model health [4, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 135 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [2.0, 5.0], model VP 1, enemy VP 5, victory condition 1
Iteration 136 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [2.0, 5.0], model VP 1, enemy VP 8, victory condition 1
Iteration 137 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [0.0, 5.0], model VP 1, enemy VP 11, victory condition 1
Iteration 138 ended with reward tensor([-2.5000]), enemy health [1.0, 8], model health [0.0, 4.0], model VP 0, enemy VP 3, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 139 ended with reward tensor([-0.8000]), enemy health [4, 5.0], model health [0, 8], model VP 0, enemy VP 3, victory condition 2
Iteration 140 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0, 8], model VP 0, enemy VP 6, victory condition 2
Iteration 141 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0, 8.0], model VP 0, enemy VP 9, victory condition 2
Iteration 142 ended with reward tensor([-2.8000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 12, victory condition 2
Iteration 143 ended with reward tensor([-4]), enemy health [4, 0], model health [0, 0], model VP 0, enemy VP 14, victory condition 2
Major Victory
enemy won!
Iteration 144 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 145 ended with reward tensor([-1]), enemy health [4, 5.0], model health [4, 0], model VP 0, enemy VP 4, victory condition 1
Iteration 146 ended with reward tensor([-0.8000]), enemy health [4, 5.0], model health [4.0, 0], model VP 0, enemy VP 6, victory condition 1
Iteration 147 ended with reward tensor([-4]), enemy health [4, 5.0], model health [0, 0], model VP 1, enemy VP 8, victory condition 1
Major Victory
enemy won!
Iteration 148 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [4, 8], model VP 1, enemy VP 2, victory condition 1
Iteration 149 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 4, victory condition 1
Iteration 150 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [4, 8.0], model VP 3, enemy VP 6, victory condition 1
Iteration 151 ended with reward tensor([0.9000]), enemy health [0, 8], model health [4, 8.0], model VP 4, enemy VP 8, victory condition 1
Iteration 152 ended with reward tensor([-2.]), enemy health [0, 8], model health [4, 5.0], model VP 1, enemy VP 2, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 153 ended with reward tensor([-1.]), enemy health [4, 8], model health [4, 5.0], model VP 1, enemy VP 2, victory condition 1
Iteration 154 ended with reward tensor([-1.]), enemy health [4, 8], model health [4, 5.0], model VP 2, enemy VP 4, victory condition 1
Iteration 155 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [1.0, 4.0], model VP 3, enemy VP 6, victory condition 1
Iteration 156 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [1.0, 3.0], model VP 4, enemy VP 8, victory condition 1
Iteration 157 ended with reward tensor([-3.5000]), enemy health [4, 7.0], model health [1.0, 3.0], model VP 0, enemy VP 3, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 158 ended with reward tensor([-1.]), enemy health [4, 8], model health [1.0, 8], model VP 1, enemy VP 3, victory condition 2
Iteration 159 ended with reward tensor([-1.5000]), enemy health [4, 8], model health [0, 8], model VP 2, enemy VP 6, victory condition 2
Iteration 160 ended with reward tensor([-2.3000]), enemy health [1.0, 8], model health [0, 8], model VP 2, enemy VP 9, victory condition 2
Iteration 161 ended with reward tensor([-4]), enemy health [0.0, 8], model health [0, 0], model VP 2, enemy VP 12, victory condition 2
Major Victory
enemy won!
Iteration 162 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 3, victory condition 2
Iteration 163 ended with reward tensor([-4]), enemy health [4, 8], model health [0, 0.0], model VP 0, enemy VP 6, victory condition 2
Major Victory
enemy won!
Iteration 164 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 3, victory condition 2
Iteration 165 ended with reward tensor([0.9000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 6, victory condition 2
Iteration 166 ended with reward tensor([0.5000]), enemy health [0, 8], model health [4, 5.0], model VP 1, enemy VP 8, victory condition 2
Iteration 167 ended with reward tensor([0]), enemy health [0, 8], model health [4, 5.0], model VP 2, enemy VP 10, victory condition 2
Iteration 168 ended with reward tensor([-5.5000]), enemy health [0, 8], model health [4, 5.0], model VP 3, enemy VP 12, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 169 ended with reward tensor([-4.5000]), enemy health [0, 8], model health [4, 5.0], model VP 1, enemy VP 2, victory condition 1
Iteration 170 ended with reward tensor([-0.8000]), enemy health [0, 8], model health [4, 0], model VP 2, enemy VP 4, victory condition 1
Iteration 171 ended with reward tensor([-0.3000]), enemy health [0, 8], model health [1.0, 0], model VP 3, enemy VP 6, victory condition 1
Iteration 172 ended with reward tensor([-4]), enemy health [0, 8], model health [0, 0], model VP 4, enemy VP 8, victory condition 1
Major Victory
enemy won!
Iteration 173 ended with reward tensor([0.4000]), enemy health [4, 2.0], model health [4, 5.0], model VP 1, enemy VP 2, victory condition 1
Iteration 174 ended with reward tensor([0.4000]), enemy health [4, 0], model health [1.0, 5.0], model VP 2, enemy VP 4, victory condition 1
Iteration 175 ended with reward tensor([-1.]), enemy health [4, 0], model health [1.0, 5.0], model VP 3, enemy VP 6, victory condition 1
Iteration 176 ended with reward tensor([-1.]), enemy health [4, 0], model health [1.0, 5.0], model VP 4, enemy VP 8, victory condition 1
Iteration 177 ended with reward tensor([-6.]), enemy health [4, 0], model health [1.0, 5.0], model VP 1, enemy VP 2, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 178 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [4, 8], model VP 1, enemy VP 2, victory condition 2
Iteration 179 ended with reward tensor([0.]), enemy health [1.0, 8], model health [4, 8], model VP 2, enemy VP 4, victory condition 2
Iteration 180 ended with reward tensor([0.]), enemy health [1.0, 8], model health [4, 8], model VP 3, enemy VP 6, victory condition 2
Iteration 181 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [4, 8], model VP 4, enemy VP 8, victory condition 2
Iteration 182 ended with reward tensor([-1.8000]), enemy health [1.0, 8], model health [4, 8], model VP 5, enemy VP 10, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 183 ended with reward tensor([-3.5000]), enemy health [4, 8], model health [4, 8], model VP 1, enemy VP 2, victory condition 2
Iteration 184 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 4, victory condition 2
Iteration 185 ended with reward tensor([-3.5000]), enemy health [4, 8], model health [4, 8], model VP 3, enemy VP 6, victory condition 2
Iteration 186 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 4, enemy VP 8, victory condition 2
Iteration 187 ended with reward tensor([-1.5000]), enemy health [4, 8], model health [4, 8], model VP 5, enemy VP 10, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 188 ended with reward tensor([-3.8000]), enemy health [1.0, 8], model health [4, 2.0], model VP 2, enemy VP 2, victory condition 1
Iteration 189 ended with reward tensor([-1]), enemy health [1.0, 8], model health [4, 0.0], model VP 4, enemy VP 4, victory condition 1
Iteration 190 ended with reward tensor([-1]), enemy health [1.0, 8], model health [4, 0.0], model VP 6, enemy VP 6, victory condition 1
Iteration 191 ended with reward tensor([-1]), enemy health [1.0, 8], model health [1.0, 0], model VP 8, enemy VP 8, victory condition 1
Iteration 192 ended with reward tensor([-4]), enemy health [1.0, 8], model health [0, 0.0], model VP 10, enemy VP 10, victory condition 1
Major Victory
enemy won!
Iteration 193 ended with reward tensor([-3.5000]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 2, victory condition 1
Iteration 194 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 4, enemy VP 4, victory condition 1
Iteration 195 ended with reward tensor([-4.]), enemy health [4, 8], model health [4, 8], model VP 6, enemy VP 6, victory condition 1
Iteration 196 ended with reward tensor([-1]), enemy health [4, 8], model health [4, 0], model VP 8, enemy VP 8, victory condition 1
Iteration 197 ended with reward tensor([-3]), enemy health [4, 8], model health [4, 0], model VP 2, enemy VP 2, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 198 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [4, 5.0], model VP 2, enemy VP 2, victory condition 1
Iteration 199 ended with reward tensor([-1.5000]), enemy health [0, 8], model health [0, 2.0], model VP 4, enemy VP 4, victory condition 1
Iteration 200 ended with reward tensor([-0.3000]), enemy health [0, 2.0], model health [0, 2.0], model VP 5, enemy VP 6, victory condition 1
Iteration 201 ended with reward tensor([-4]), enemy health [0, 2.0], model health [0, 0], model VP 6, enemy VP 8, victory condition 1
Major Victory
enemy won!
Iteration 202 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 1, enemy VP 2, victory condition 1
Iteration 203 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 4, victory condition 1
Iteration 204 ended with reward tensor([-4.5000]), enemy health [4, 8], model health [4, 5.0], model VP 3, enemy VP 6, victory condition 1
Iteration 205 ended with reward tensor([-4.5000]), enemy health [4, 8], model health [4, 5.0], model VP 4, enemy VP 8, victory condition 1
Iteration 206 ended with reward tensor([-2.8000]), enemy health [4, 2.0], model health [0, 5.0], model VP 1, enemy VP 2, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 207 ended with reward tensor([1.4000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 208 ended with reward tensor([0.2000]), enemy health [1.0, 5.0], model health [1.0, 8], model VP 2, enemy VP 3, victory condition 1
Iteration 209 ended with reward tensor([-0.8000]), enemy health [0, 5.0], model health [0, 8], model VP 4, enemy VP 4, victory condition 1
Iteration 210 ended with reward tensor([-1]), enemy health [0, 5.0], model health [0, 8], model VP 6, enemy VP 5, victory condition 1
Iteration 211 ended with reward tensor([1.2000]), enemy health [0, 2.0], model health [0, 8.0], model VP 2, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 212 ended with reward tensor([-4.3000]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 1, victory condition 1
Iteration 213 ended with reward tensor([-1.]), enemy health [4, 8], model health [0, 8], model VP 4, enemy VP 2, victory condition 1
Iteration 214 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0.0, 5.0], model VP 6, enemy VP 3, victory condition 1
Iteration 215 ended with reward tensor([0.7000]), enemy health [3.0, 8], model health [0.0, 5.0], model VP 8, enemy VP 4, victory condition 1
Iteration 216 ended with reward tensor([1.5000]), enemy health [3.0, 8], model health [0.0, 5.0], model VP 2, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 217 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [4, 8], model VP 2, enemy VP 1, victory condition 2
Iteration 218 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [4, 5.0], model VP 4, enemy VP 2, victory condition 2
Iteration 219 ended with reward tensor([-0.5000]), enemy health [1.0, 5.0], model health [1.0, 5.0], model VP 4, enemy VP 3, victory condition 2
Iteration 220 ended with reward tensor([-2.5000]), enemy health [1.0, 5.0], model health [0, 0.0], model VP 4, enemy VP 4, victory condition 2
Major Victory
enemy won!
Iteration 221 ended with reward tensor([0.7000]), enemy health [4, 2.0], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 222 ended with reward tensor([-3.8000]), enemy health [4, 0], model health [4, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 223 ended with reward tensor([0.5000]), enemy health [4, 0], model health [4, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 224 ended with reward tensor([0]), enemy health [4, 0], model health [4, 5.0], model VP 0, enemy VP 4, victory condition 1
Iteration 225 ended with reward tensor([-2]), enemy health [4, 0], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 226 ended with reward tensor([0.4000]), enemy health [4, 0], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 227 ended with reward tensor([1.]), enemy health [3.0, 0], model health [4, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 228 ended with reward tensor([1.5000]), enemy health [0.0, 0], model health [0, 5.0], model VP 3, enemy VP 2, victory condition 1
Major Victory
model won!
Iteration 229 ended with reward tensor([0.7000]), enemy health [4, 2.0], model health [4, 8], model VP 2, enemy VP 0, victory condition 2
Iteration 230 ended with reward tensor([-3.1000]), enemy health [1.0, 2.0], model health [4, 5.0], model VP 4, enemy VP 0, victory condition 2
Iteration 231 ended with reward tensor([1.4000]), enemy health [0, 2.0], model health [4, 2.0], model VP 6, enemy VP 1, victory condition 2
Iteration 232 ended with reward tensor([3.]), enemy health [0, 0.0], model health [4.0, 2.0], model VP 8, enemy VP 1, victory condition 2
Major Victory
model won!
Iteration 233 ended with reward tensor([1.4000]), enemy health [4, 5.0], model health [4, 2.0], model VP 2, enemy VP 0, victory condition 2
Iteration 234 ended with reward tensor([-0.8000]), enemy health [4, 2.0], model health [0.0, 2.0], model VP 4, enemy VP 0, victory condition 2
Iteration 235 ended with reward tensor([-4]), enemy health [4, 2.0], model health [0.0, 0], model VP 6, enemy VP 2, victory condition 2
Major Victory
enemy won!
Iteration 236 ended with reward tensor([-0.8000]), enemy health [4, 8], model health [4, 0], model VP 2, enemy VP 2, victory condition 2
Iteration 237 ended with reward tensor([-3.5000]), enemy health [4, 8], model health [0, 0], model VP 4, enemy VP 4, victory condition 2
Major Victory
enemy won!
Iteration 238 ended with reward tensor([-2.8000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 239 ended with reward tensor([-3.3000]), enemy health [4, 8], model health [1.0, 8], model VP 2, enemy VP 4, victory condition 1
Iteration 240 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 4, enemy VP 5, victory condition 1
Iteration 241 ended with reward tensor([0.7000]), enemy health [4, 8], model health [0, 5.0], model VP 6, enemy VP 6, victory condition 1
Iteration 242 ended with reward tensor([1.5000]), enemy health [4, 8], model health [0, 2.0], model VP 2, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 243 ended with reward tensor([-3.8000]), enemy health [0, 8], model health [4, 8], model VP 2, enemy VP 0, victory condition 1
Iteration 244 ended with reward tensor([0.5000]), enemy health [0, 8], model health [4, 8], model VP 4, enemy VP 0, victory condition 1
Iteration 245 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [4, 2.0], model VP 6, enemy VP 0, victory condition 1
Iteration 246 ended with reward tensor([2.7000]), enemy health [0, 0], model health [4, 2.0], model VP 8, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 247 ended with reward tensor([0.]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 1, victory condition 1
Iteration 248 ended with reward tensor([0.5000]), enemy health [4, 8], model health [1.0, 8], model VP 4, enemy VP 2, victory condition 1
Iteration 249 ended with reward tensor([0.4000]), enemy health [0, 8], model health [1.0, 8], model VP 4, enemy VP 3, victory condition 1
Iteration 250 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [1.0, 5.0], model VP 4, enemy VP 5, victory condition 1
Iteration 251 ended with reward tensor([-3.]), enemy health [0, 5.0], model health [1.0, 2.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 252 ended with reward tensor([-4.3000]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 253 ended with reward tensor([0]), enemy health [4, 8], model health [1.0, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 254 ended with reward tensor([-0.3000]), enemy health [1.0, 8], model health [1.0, 0.0], model VP 2, enemy VP 3, victory condition 1
Iteration 255 ended with reward tensor([-0.8000]), enemy health [1.0, 8], model health [1.0, 0.0], model VP 4, enemy VP 3, victory condition 1
Iteration 256 ended with reward tensor([-3.5000]), enemy health [1.0, 8], model health [0.0, 0.0], model VP 6, enemy VP 3, victory condition 1
Major Victory
enemy won!
Iteration 257 ended with reward tensor([0.9000]), enemy health [4, 5.0], model health [0, 8], model VP 2, enemy VP 0, victory condition 1
Iteration 258 ended with reward tensor([-4]), enemy health [4, 5.0], model health [0, 0], model VP 4, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 259 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 0, victory condition 2
Iteration 260 ended with reward tensor([-0.3000]), enemy health [4, 5.0], model health [0, 8], model VP 4, enemy VP 0, victory condition 2
Iteration 261 ended with reward tensor([-4]), enemy health [4, 5.0], model health [0, 0], model VP 6, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 262 ended with reward tensor([0.9000]), enemy health [4, 5.0], model health [4, 2.0], model VP 3, enemy VP 0, victory condition 1
Iteration 263 ended with reward tensor([-3.5000]), enemy health [4, 5.0], model health [0, 0], model VP 6, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 264 ended with reward tensor([0.9000]), enemy health [4, 0], model health [4, 5.0], model VP 3, enemy VP 0, victory condition 2
Iteration 265 ended with reward tensor([2.7000]), enemy health [0, 0], model health [4, 5.0], model VP 6, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 266 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [1.0, 8], model VP 3, enemy VP 0, victory condition 2
Iteration 267 ended with reward tensor([-2.3000]), enemy health [1.0, 5.0], model health [0, 8.0], model VP 6, enemy VP 0, victory condition 2
Iteration 268 ended with reward tensor([-0.3000]), enemy health [1.0, 0], model health [0, 5.0], model VP 9, enemy VP 0, victory condition 2
Iteration 269 ended with reward tensor([-1.]), enemy health [1.0, 0], model health [0, 2.0], model VP 12, enemy VP 0, victory condition 2
Iteration 270 ended with reward tensor([-4]), enemy health [1.0, 0], model health [0, 0], model VP 15, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 271 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 3, enemy VP 0, victory condition 1
Iteration 272 ended with reward tensor([-3.5000]), enemy health [4, 8], model health [4, 8], model VP 6, enemy VP 0, victory condition 1
Iteration 273 ended with reward tensor([-4.]), enemy health [4, 8], model health [4, 8], model VP 9, enemy VP 0, victory condition 1
Iteration 274 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [4, 5.0], model VP 12, enemy VP 0, victory condition 1
Iteration 275 ended with reward tensor([-1.8000]), enemy health [4.0, 5.0], model health [4, 5.0], model VP 3, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 276 ended with reward tensor([-1]), enemy health [4, 8], model health [0, 8], model VP 3, enemy VP 0, victory condition 2
Iteration 277 ended with reward tensor([0.7000]), enemy health [2.0, 8], model health [0, 8], model VP 7, enemy VP 0, victory condition 2
Iteration 278 ended with reward tensor([1.]), enemy health [0, 8], model health [0, 8], model VP 11, enemy VP 0, victory condition 2
Iteration 279 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 8], model VP 14, enemy VP 0, victory condition 2
Iteration 280 ended with reward tensor([1.5000]), enemy health [0, 8], model health [0, 4.0], model VP 17, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 281 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 5.0], model VP 3, enemy VP 0, victory condition 1
Iteration 282 ended with reward tensor([-1.]), enemy health [4, 5.0], model health [1.0, 5.0], model VP 6, enemy VP 0, victory condition 1
Iteration 283 ended with reward tensor([-0.3000]), enemy health [4, 0], model health [0, 2.0], model VP 8, enemy VP 0, victory condition 1
Iteration 284 ended with reward tensor([-1.5000]), enemy health [1.0, 0], model health [0, 2.0], model VP 12, enemy VP 0, victory condition 1
Iteration 285 ended with reward tensor([-4]), enemy health [1.0, 0], model health [0, 0], model VP 16, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 286 ended with reward tensor([-1]), enemy health [4, 8], model health [4, 0], model VP 4, enemy VP 0, victory condition 1
Iteration 287 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [4, 0], model VP 8, enemy VP 0, victory condition 1
Iteration 288 ended with reward tensor([-1.]), enemy health [4, 8], model health [4, 0], model VP 12, enemy VP 0, victory condition 1
Iteration 289 ended with reward tensor([-0.3000]), enemy health [4, 8.0], model health [1.0, 0], model VP 13, enemy VP 0, victory condition 1
Iteration 290 ended with reward tensor([-4]), enemy health [4, 8.0], model health [0, 0], model VP 14, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 291 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 1, enemy VP 0, victory condition 1
Iteration 292 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0.0, 8], model VP 2, enemy VP 0, victory condition 1
Iteration 293 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0.0, 8], model VP 3, enemy VP 0, victory condition 1
Iteration 294 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [0.0, 8], model VP 4, enemy VP 0, victory condition 1
Iteration 295 ended with reward tensor([2.7000]), enemy health [4, 4.0], model health [0.0, 6.0], model VP 1, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 296 ended with reward tensor([0.9000]), enemy health [4, 2.0], model health [4.0, 8], model VP 1, enemy VP 0, victory condition 1
Iteration 297 ended with reward tensor([-0.3000]), enemy health [4, 2.0], model health [0, 8], model VP 2, enemy VP 0, victory condition 1
Iteration 298 ended with reward tensor([-2.8000]), enemy health [4, 2.0], model health [0, 5.0], model VP 3, enemy VP 0, victory condition 1
Iteration 299 ended with reward tensor([0.7000]), enemy health [3.0, 2.0], model health [0, 5.0], model VP 4, enemy VP 0, victory condition 1
Iteration 300 ended with reward tensor([-2.5000]), enemy health [3.0, 2.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 301 ended with reward tensor([0.7000]), enemy health [4, 6.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 302 ended with reward tensor([-0.5000]), enemy health [4, 6.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 303 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [0, 1.0], model VP 1, enemy VP 0, victory condition 1
Iteration 304 ended with reward tensor([-4]), enemy health [4, 5.0], model health [0, 0.0], model VP 2, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 305 ended with reward tensor([-3.5000]), enemy health [4, 8], model health [4, 8], model VP 1, enemy VP 0, victory condition 2
Iteration 306 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 2.0], model VP 2, enemy VP 0, victory condition 2
Iteration 307 ended with reward tensor([-0.3000]), enemy health [0, 5.0], model health [4, 0], model VP 3, enemy VP 0, victory condition 2
Iteration 308 ended with reward tensor([-3.5000]), enemy health [0, 5.0], model health [0, 0], model VP 7, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 309 ended with reward tensor([1.4000]), enemy health [4, 5.0], model health [4.0, 8], model VP 4, enemy VP 0, victory condition 2
Iteration 310 ended with reward tensor([-0.3000]), enemy health [4, 2.0], model health [4.0, 3.0], model VP 8, enemy VP 0, victory condition 2
Iteration 311 ended with reward tensor([-4.5000]), enemy health [4, 2.0], model health [0, 0.0], model VP 12, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 312 ended with reward tensor([0.9000]), enemy health [4, 5.0], model health [1.0, 8], model VP 2, enemy VP 0, victory condition 1
Iteration 313 ended with reward tensor([-0.3000]), enemy health [4, 2.0], model health [0, 8], model VP 4, enemy VP 0, victory condition 1
Iteration 314 ended with reward tensor([-0.3000]), enemy health [4, 0], model health [0, 8.0], model VP 6, enemy VP 0, victory condition 1
Iteration 315 ended with reward tensor([-1.]), enemy health [4, 0], model health [0, 8.0], model VP 8, enemy VP 0, victory condition 1
Iteration 316 ended with reward tensor([1.]), enemy health [4, 0], model health [0, 8.0], model VP 2, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 317 ended with reward tensor([0.9000]), enemy health [4, 2.0], model health [4, 8], model VP 2, enemy VP 0, victory condition 2
Iteration 318 ended with reward tensor([0.2000]), enemy health [4, 0], model health [4, 5.0], model VP 4, enemy VP 0, victory condition 2
Iteration 319 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [4, 5.0], model VP 6, enemy VP 0, victory condition 2
Iteration 320 ended with reward tensor([0.9000]), enemy health [1.0, 0], model health [4, 5.0], model VP 8, enemy VP 0, victory condition 2
Iteration 321 ended with reward tensor([1.5000]), enemy health [1.0, 0], model health [4, 5.0], model VP 10, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 322 ended with reward tensor([-4.3000]), enemy health [4, 8], model health [1.0, 8.0], model VP 2, enemy VP 0, victory condition 1
Iteration 323 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [0, 5.0], model VP 4, enemy VP 0, victory condition 1
Iteration 324 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 2.0], model VP 4, enemy VP 0, victory condition 1
Iteration 325 ended with reward tensor([0.7000]), enemy health [3.0, 8], model health [0, 1.0], model VP 4, enemy VP 0, victory condition 1
Iteration 326 ended with reward tensor([-2]), enemy health [3.0, 8], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 327 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [4, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 328 ended with reward tensor([0.9000]), enemy health [4, 5.0], model health [4, 2.0], model VP 2, enemy VP 0, victory condition 1
Iteration 329 ended with reward tensor([0]), enemy health [4, 5.0], model health [0.0, 2.0], model VP 4, enemy VP 0, victory condition 1
Iteration 330 ended with reward tensor([-4]), enemy health [4, 5.0], model health [0.0, 0], model VP 6, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 331 ended with reward tensor([-0.8000]), enemy health [0, 8], model health [0, 2.0], model VP 2, enemy VP 0, victory condition 1
Iteration 332 ended with reward tensor([-4]), enemy health [0, 8], model health [0, 0], model VP 4, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 333 ended with reward tensor([-4.]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 0, victory condition 1
Iteration 334 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 4, enemy VP 0, victory condition 1
Iteration 335 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 6, enemy VP 0, victory condition 1
Iteration 336 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 8, enemy VP 0, victory condition 1
Iteration 337 ended with reward tensor([1.2000]), enemy health [4, 8], model health [4, 0], model VP 2, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 338 ended with reward tensor([-2.8000]), enemy health [4, 8], model health [1.0, 8], model VP 1, enemy VP 0, victory condition 2
Iteration 339 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 2, enemy VP 0, victory condition 2
Iteration 340 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 3, enemy VP 0, victory condition 2
Iteration 341 ended with reward tensor([0.7000]), enemy health [2.0, 8], model health [0, 5.0], model VP 4, enemy VP 0, victory condition 2
Iteration 342 ended with reward tensor([1.5000]), enemy health [2.0, 8], model health [0, 5.0], model VP 5, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 343 ended with reward tensor([0.9000]), enemy health [4, 5.0], model health [4, 5.0], model VP 1, enemy VP 0, victory condition 1
Iteration 344 ended with reward tensor([-0.3000]), enemy health [4, 2.0], model health [0.0, 5.0], model VP 2, enemy VP 0, victory condition 1
Iteration 345 ended with reward tensor([-4]), enemy health [4, 2.0], model health [0.0, 0.0], model VP 3, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 346 ended with reward tensor([-3.1000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 347 ended with reward tensor([-0.3000]), enemy health [0, 8], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 348 ended with reward tensor([-3.5000]), enemy health [0, 8], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 349 ended with reward tensor([-0.3000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 350 ended with reward tensor([1.5000]), enemy health [0, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 351 ended with reward tensor([0.9000]), enemy health [4, 0], model health [1.0, 8], model VP 3, enemy VP 0, victory condition 1
Iteration 352 ended with reward tensor([0.]), enemy health [4, 0], model health [1.0, 8], model VP 5, enemy VP 0, victory condition 1
Iteration 353 ended with reward tensor([0.9000]), enemy health [1.0, 0], model health [1.0, 8], model VP 7, enemy VP 0, victory condition 1
Iteration 354 ended with reward tensor([3.7000]), enemy health [0, 0], model health [0, 8], model VP 9, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 355 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 0, victory condition 1
Iteration 356 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 4, enemy VP 0, victory condition 1
Iteration 357 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 6, enemy VP 0, victory condition 1
Iteration 358 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 8, enemy VP 0, victory condition 1
Iteration 359 ended with reward tensor([2.2000]), enemy health [4.0, 8], model health [4, 8], model VP 2, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 360 ended with reward tensor([-1]), enemy health [4, 8], model health [4, 0], model VP 2, enemy VP 0, victory condition 2
Iteration 361 ended with reward tensor([-1]), enemy health [4, 8], model health [4, 0], model VP 4, enemy VP 0, victory condition 2
Iteration 362 ended with reward tensor([-1]), enemy health [4, 8], model health [4, 0], model VP 6, enemy VP 0, victory condition 2
Iteration 363 ended with reward tensor([-1]), enemy health [4, 8], model health [4, 0], model VP 8, enemy VP 0, victory condition 2
Iteration 364 ended with reward tensor([1.]), enemy health [4, 8], model health [4, 0], model VP 16, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 365 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [4, 2.0], model VP 4, enemy VP 0, victory condition 2
Iteration 366 ended with reward tensor([-2.5000]), enemy health [4, 2.0], model health [4, 0], model VP 8, enemy VP 0, victory condition 2
Iteration 367 ended with reward tensor([-0.5000]), enemy health [4, 2.0], model health [4, 0], model VP 12, enemy VP 0, victory condition 2
Iteration 368 ended with reward tensor([-0.5000]), enemy health [4, 2.0], model health [1.0, 0], model VP 14, enemy VP 0, victory condition 2
Iteration 369 ended with reward tensor([1.7000]), enemy health [4, 2.0], model health [1.0, 0], model VP 24, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 370 ended with reward tensor([0.7000]), enemy health [4, 8.0], model health [4, 2.0], model VP 2, enemy VP 0, victory condition 1
Iteration 371 ended with reward tensor([-3.]), enemy health [4, 8.0], model health [4.0, 0], model VP 4, enemy VP 0, victory condition 1
Iteration 372 ended with reward tensor([-4]), enemy health [4, 8.0], model health [0, 0], model VP 6, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 373 ended with reward tensor([-1.]), enemy health [4, 8], model health [4.0, 8], model VP 2, enemy VP 0, victory condition 2
Iteration 374 ended with reward tensor([-3.6000]), enemy health [4, 2.0], model health [0.0, 8], model VP 4, enemy VP 0, victory condition 2
Iteration 375 ended with reward tensor([-0.3000]), enemy health [4, 0], model health [0.0, 2.0], model VP 8, enemy VP 0, victory condition 2
Iteration 376 ended with reward tensor([-1]), enemy health [4, 0], model health [0.0, 2.0], model VP 10, enemy VP 0, victory condition 2
Iteration 377 ended with reward tensor([-4]), enemy health [4, 0], model health [0.0, 0], model VP 12, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 378 ended with reward tensor([0.]), enemy health [4, 8], model health [4, 8], model VP 2, enemy VP 0, victory condition 1
Iteration 379 ended with reward tensor([0.]), enemy health [4, 8], model health [1.0, 8], model VP 4, enemy VP 0, victory condition 1
Iteration 380 ended with reward tensor([0.7000]), enemy health [1.0, 8], model health [1.0, 8], model VP 6, enemy VP 0, victory condition 1
Iteration 381 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [0, 8], model VP 8, enemy VP 0, victory condition 1
Iteration 382 ended with reward tensor([1.7000]), enemy health [1.0, 2.0], model health [0, 2.0], model VP 2, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 383 ended with reward tensor([0.5000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 384 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [1.0, 8], model VP 2, enemy VP 0, victory condition 2
Iteration 385 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0, 8], model VP 4, enemy VP 0, victory condition 2
Iteration 386 ended with reward tensor([-1]), enemy health [4, 5.0], model health [0, 8], model VP 6, enemy VP 0, victory condition 2
Iteration 387 ended with reward tensor([1.5000]), enemy health [4, 5.0], model health [0, 8], model VP 14, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 388 ended with reward tensor([-1.5000]), enemy health [4, 2.0], model health [4, 0], model VP 2, enemy VP 0, victory condition 1
Iteration 389 ended with reward tensor([-3.5000]), enemy health [4, 2.0], model health [0, 0], model VP 4, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 390 ended with reward tensor([-1.]), enemy health [4, 8], model health [4, 2.0], model VP 4, enemy VP 0, victory condition 1
Iteration 391 ended with reward tensor([0.4000]), enemy health [4, 5.0], model health [1.0, 2.0], model VP 8, enemy VP 0, victory condition 1
Iteration 392 ended with reward tensor([-3.5000]), enemy health [4, 5.0], model health [0, 0], model VP 12, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 393 ended with reward tensor([-0.3000]), enemy health [4, 5.0], model health [0, 8], model VP 4, enemy VP 0, victory condition 1
Iteration 394 ended with reward tensor([-0.3000]), enemy health [4, 0], model health [0, 5.0], model VP 8, enemy VP 0, victory condition 1
Iteration 395 ended with reward tensor([1.7000]), enemy health [0, 0], model health [0, 5.0], model VP 12, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 396 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 4, enemy VP 0, victory condition 2
Iteration 397 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 8, enemy VP 0, victory condition 2
Iteration 398 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 12, enemy VP 0, victory condition 2
Iteration 399 ended with reward tensor([-3.5000]), enemy health [4, 8], model health [4, 8], model VP 16, enemy VP 0, victory condition 2
Iteration 400 ended with reward tensor([2.5000]), enemy health [4, 8], model health [4, 8], model VP 26, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 401 ended with reward tensor([0.9000]), enemy health [1.0, 5.0], model health [4.0, 8], model VP 4, enemy VP 0, victory condition 1
Iteration 402 ended with reward tensor([1.]), enemy health [0, 5.0], model health [4.0, 8], model VP 8, enemy VP 0, victory condition 1
Iteration 403 ended with reward tensor([2.9000]), enemy health [0, 0.0], model health [4.0, 8], model VP 12, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 404 ended with reward tensor([0.7000]), enemy health [4, 8], model health [4, 8], model VP 4, enemy VP 0, victory condition 1
Iteration 405 ended with reward tensor([1.2000]), enemy health [4, 8], model health [1.0, 8], model VP 6, enemy VP 0, victory condition 1
Iteration 406 ended with reward tensor([-1.]), enemy health [4, 8], model health [0, 8], model VP 8, enemy VP 0, victory condition 1
Iteration 407 ended with reward tensor([-0.8000]), enemy health [0, 8], model health [0, 8], model VP 10, enemy VP 0, victory condition 1
Iteration 408 ended with reward tensor([1.5000]), enemy health [0, 8], model health [0, 8], model VP 2, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 409 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 8.0], model VP 2, enemy VP 0, victory condition 1
Iteration 410 ended with reward tensor([0.]), enemy health [0, 8], model health [4, 2.0], model VP 5, enemy VP 0, victory condition 1
Iteration 411 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [4, 2.0], model VP 5, enemy VP 0, victory condition 1
Iteration 412 ended with reward tensor([2.7000]), enemy health [0, 0], model health [4, 2.0], model VP 8, enemy VP 0, victory condition 1
Major Victory
model won!
